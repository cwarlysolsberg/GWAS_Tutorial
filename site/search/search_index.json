{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 Overview \u00b6 This tutorial provides a step-by-step guide to performing basic Genome Wide Association Study (GWAS) analyses and accompanies our GWAS Guide paper . The aim of this tutorial is to provide a simple introduction of GWAS analyses while equipping existing users with a better understanding of the processes and implementation of mainstay GWAS tools. The tutorial is separated into five main section. Quality Control of GWAS Data Population Stratification Association Analyses Visualizing of Association results Deep dive into underpinnings of associations Warning Data used in this tutorial are simulated and intended for demonstration purposes only. The results from this tutorial will not reflect the true performance of different software. Notes We assume you have basic knownledges on how to use the terminal, plink and R . If you are unfamiliar with any of those, you can refer to the following online resources: Software link terminal (OS X / Linux) 1 , 2 terminal (Windows) 1 , 2 plink v1.90 , v1.75 R 1 Note This tutorial is written for Linux and OS X operating systems. Windows users will need to change some commands accordingly. Requirements \u00b6 To follow the tutorial, you will need the following programs installed: R ( version 3.2.3+ ) PLINK 1.9 Citation \u00b6 If you find this tutorial helpful for a publication, then please consider citing: Citation","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#overview","text":"This tutorial provides a step-by-step guide to performing basic Genome Wide Association Study (GWAS) analyses and accompanies our GWAS Guide paper . The aim of this tutorial is to provide a simple introduction of GWAS analyses while equipping existing users with a better understanding of the processes and implementation of mainstay GWAS tools. The tutorial is separated into five main section. Quality Control of GWAS Data Population Stratification Association Analyses Visualizing of Association results Deep dive into underpinnings of associations Warning Data used in this tutorial are simulated and intended for demonstration purposes only. The results from this tutorial will not reflect the true performance of different software. Notes We assume you have basic knownledges on how to use the terminal, plink and R . If you are unfamiliar with any of those, you can refer to the following online resources: Software link terminal (OS X / Linux) 1 , 2 terminal (Windows) 1 , 2 plink v1.90 , v1.75 R 1 Note This tutorial is written for Linux and OS X operating systems. Windows users will need to change some commands accordingly.","title":"Overview"},{"location":"#requirements","text":"To follow the tutorial, you will need the following programs installed: R ( version 3.2.3+ ) PLINK 1.9","title":"Requirements"},{"location":"#citation","text":"If you find this tutorial helpful for a publication, then please consider citing: Citation","title":"Citation"},{"location":"QC/","text":"QC of HapMap3 data \u00b6 Obtaining and visualizing missingness in the HapMap data files \u00b6 The first step in GWAS analyses is to generate or obtain the genotype or sequencing data. Ideally these will be in Plink format (.bim,.bed,.fam) You can download the HapMap example data here You MUST download and unzip the R folder from here as well to run downstream scripts. Note Due to limitation to bandwidth, we are currently using google drive to host the files, which doesn't allow the use of wget or curl to download the file. Please download the files manually. Warning / )) Reading the genotype data file and produce missingness data: \u00b6 We will set a fileset variable to make it easier to adjust all downstream code and then produce SNP and individual missingness data: FILESET=HapMap_3_r3_1 plink -bfile $FILESET --missing This will print a plink.imiss and plink.lmiss output file with the individual and SNP missingness data, respectively. The plink.imiss file contains the following columns: FID IID MISS_PHENO N_MISS N_GENO F_MISS 1328 NA06989 N 4203 1457897 0.002883 1377 NA11891 N 20787 1457897 0.01426 1349 NA11843 N 1564 1457897 0.001073 The column headers correspond to the following: FID : Family ID IID : Individual ID MISS_PHENO : Missing phenotype? (Y/N) N_MISS : Number of missing SNPs N_GENO : Number of non-obligatory missing genotypes F_MISS : Proportion of missing SNPs Generate Histogram to View Missingness. \u00b6 Performed in R indmiss<-read.table(file=\"plink.imiss\", header=TRUE) snpmiss<-read.table(file=\"plink.lmiss\", header=TRUE) # read data into R png(\"histimiss.png\") #indicates pdf format and gives title to file hist(indmiss[,6],main=\"Histogram individual missingness\") #selects column 6, names header of file dev.off() png(\"histlmiss.png\") hist(snpmiss[,5],main=\"Histogram SNP missingness\") dev.off() # shuts down the current device An example bar plot generated using script in hist_miss.R Filtering steps \u00b6 Filter on missingness \u00b6 We want to begin performing quality control filtering on the data. We begin with organizing our file naming convention and define our starting filter values. sep=\"_\" TAG_GENO=\"geno\" GENO=0.02 TAG_MIND=\"mind\" MIND=0.02 OUT=\"$FILESET$sep$TAG_GENO\" OUT1=\"$FILESET$sep$TAG_GENO$sep$TAG_MIND\" In is important to filter on SNP missingness (--geno) prior to filtering on individual missingness (--mind). plink --bfile $FILESET --geno $GENO --make-bed --out $OUT plink --bfile $OUT --mind $MIND --make-bed --out $OUT1 Check for Sex Discrepancies \u00b6 Note if you have not already done so, YOU MUST use the split-x command to remove the psuedo autosomal region Performed in R gender <- read.table(\"plink.sexcheck\", header=T,as.is=T) pdf(\"Gender_check.pdf\") hist(gender[,6],main=\"Gender\", xlab=\"F\") dev.off() pdf(\"Men_check.pdf\") male=subset(gender, gender$PEDSEX==1) hist(male[,6],main=\"Men\",xlab=\"F\") dev.off() pdf(\"Women_check.pdf\") female=subset(gender, gender$PEDSEX==2) hist(female[,6],main=\"Women\",xlab=\"F\") dev.off() Remove SNPS that do not pass the sex check. rem=\"rem\" OUT2=$OUT1$sep$rem # This command generates a list of individuals with the status ?PROBLEM?. grep \"PROBLEM\" plink.sexcheck| awk '{print$1,$2}'> sex_discrepancy.txt plink --bfile $OUT1 --remove sex_discrepancy.txt --make-bed --out $OUT2 Limit data to autosomal SNPs only \u00b6 We wll generate a txt file with all the SNPS on the autosomes so that we can remove all SNPS that are on the sex chromosomes or in mitochondrial DND. BIM=\".bim\" AUTOSOME=\"autosome\" OUT3=$OUT2$sep$AUTOSOME awk '{ if ($1 >= 1 && $1 <= 23) print $2 }' $OUT2$BIM > snp_1_22.txt plink --bfile $OUT2 --extract snp_1_22.txt --make-bed --out $OUT3 Perform MAF check and filter by MAF Threshold \u00b6 plink --bfile $OUT2 --freq --out MAF_check Performed in R maf_freq <- read.table(\"MAF_check.frq\", header =TRUE, as.is=T) pdf(\"MAF_distribution.pdf\") hist(maf_freq[,5],main = \"MAF distribution\", xlab = \"MAF\") dev.off() Now we want to filter out any SNPS with a MAF<0.05 for a small data set or 0.1 for a larger data set. TAG_MAF=\"maf\" OUT3=$OUT2$sep$TAG_MAF MAF=0.05 plink --bfile $OUT2 --maf $MAF --make-bed --out $OUT3 View heterozygosity distribution and remove outliers \u00b6 Generate a pruned subset of SNPs that are in approximate linkage equilibrium. plink --bfile $OUT3 --indep-pairwise 50 5 0.5 Compute method-of-moments F coefficient estimates The --het flag in Plink computes observed and expected autosomal homozygous genotype counts for each sample, and reports method-of-moments F coefficient estimates (i.e. ( - ) / ( - )) to R_check.het. plink --bfile $OUT3 --extract plink.prune.in --het --out R_check Plot of the heterozygosity rate distribution generated in R het <- read.table(\"R_check.het\", head=TRUE) pdf(\"heterozygosity.pdf\") het$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\" hist(het$HET_RATE, xlab=\"Heterozygosity Rate\", ylab=\"Frequency\", main= \"Heterozygosity Rate\") dev.off() list of individuals who deviate more than 3 standard deviations from the heterozygosity rate mean generated in R het <- read.table(\"R_check.het\", head=TRUE) het$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\" het_fail = subset(het, (het$HET_RATE < mean(het$HET_RATE)-3*sd(het$HET_RATE)) | (het$HET_RATE > mean(het$HET_RATE)+3*sd(het$HET_RATE))); het_fail$HET_DST = (het_fail$HET_RATE-mean(het$HET_RATE))/sd(het$HET_RATE); write.table(het_fail, \"fail-het-qc.txt\", row.names=FALSE) The command above generates the fail-het-qc.txt file and the command below saves the first two rows to a new file named het_fail_ind.txt sed 's/\"// g' fail-het-qc.txt | awk '{print$1, $2}' > het_fail_ind.txt remove individuals that are heterozygous outliers HET=\"het_fix\" OUT4=$OUT3$sep$HET plink --bfile $OUT3 --remove het_fail_ind.txt --make-bed --out $OUT4 Transfer files to use for population stratification \u00b6 rename files and copy to population stratification folder mkdir 2_Population_stratification bed=\".bed\" fam=\".fam\" bim=\".bim\" mv $OUT4$bed ./qcout.bed mv $OUT4$bim ./qcout.bim mv $OUT4$fam ./qcout.fam cp qcout* 2_Population_stratification cp plink.prune.in 2_Population_stratification change directory into population stratification folder cd 2_Population_stratification","title":"1. Quality Control of GWAS Data"},{"location":"QC/#qc-of-hapmap3-data","text":"","title":"QC of HapMap3 data"},{"location":"QC/#obtaining-and-visualizing-missingness-in-the-hapmap-data-files","text":"The first step in GWAS analyses is to generate or obtain the genotype or sequencing data. Ideally these will be in Plink format (.bim,.bed,.fam) You can download the HapMap example data here You MUST download and unzip the R folder from here as well to run downstream scripts. Note Due to limitation to bandwidth, we are currently using google drive to host the files, which doesn't allow the use of wget or curl to download the file. Please download the files manually. Warning / ))","title":"Obtaining and visualizing missingness in the HapMap data files"},{"location":"QC/#reading-the-genotype-data-file-and-produce-missingness-data","text":"We will set a fileset variable to make it easier to adjust all downstream code and then produce SNP and individual missingness data: FILESET=HapMap_3_r3_1 plink -bfile $FILESET --missing This will print a plink.imiss and plink.lmiss output file with the individual and SNP missingness data, respectively. The plink.imiss file contains the following columns: FID IID MISS_PHENO N_MISS N_GENO F_MISS 1328 NA06989 N 4203 1457897 0.002883 1377 NA11891 N 20787 1457897 0.01426 1349 NA11843 N 1564 1457897 0.001073 The column headers correspond to the following: FID : Family ID IID : Individual ID MISS_PHENO : Missing phenotype? (Y/N) N_MISS : Number of missing SNPs N_GENO : Number of non-obligatory missing genotypes F_MISS : Proportion of missing SNPs","title":"Reading the genotype data file and produce missingness data:"},{"location":"QC/#generate-histogram-to-view-missingness","text":"Performed in R indmiss<-read.table(file=\"plink.imiss\", header=TRUE) snpmiss<-read.table(file=\"plink.lmiss\", header=TRUE) # read data into R png(\"histimiss.png\") #indicates pdf format and gives title to file hist(indmiss[,6],main=\"Histogram individual missingness\") #selects column 6, names header of file dev.off() png(\"histlmiss.png\") hist(snpmiss[,5],main=\"Histogram SNP missingness\") dev.off() # shuts down the current device An example bar plot generated using script in hist_miss.R","title":"Generate Histogram to View Missingness."},{"location":"QC/#filtering-steps","text":"","title":"Filtering steps"},{"location":"QC/#filter-on-missingness","text":"We want to begin performing quality control filtering on the data. We begin with organizing our file naming convention and define our starting filter values. sep=\"_\" TAG_GENO=\"geno\" GENO=0.02 TAG_MIND=\"mind\" MIND=0.02 OUT=\"$FILESET$sep$TAG_GENO\" OUT1=\"$FILESET$sep$TAG_GENO$sep$TAG_MIND\" In is important to filter on SNP missingness (--geno) prior to filtering on individual missingness (--mind). plink --bfile $FILESET --geno $GENO --make-bed --out $OUT plink --bfile $OUT --mind $MIND --make-bed --out $OUT1","title":"Filter on missingness"},{"location":"QC/#check-for-sex-discrepancies","text":"Note if you have not already done so, YOU MUST use the split-x command to remove the psuedo autosomal region Performed in R gender <- read.table(\"plink.sexcheck\", header=T,as.is=T) pdf(\"Gender_check.pdf\") hist(gender[,6],main=\"Gender\", xlab=\"F\") dev.off() pdf(\"Men_check.pdf\") male=subset(gender, gender$PEDSEX==1) hist(male[,6],main=\"Men\",xlab=\"F\") dev.off() pdf(\"Women_check.pdf\") female=subset(gender, gender$PEDSEX==2) hist(female[,6],main=\"Women\",xlab=\"F\") dev.off() Remove SNPS that do not pass the sex check. rem=\"rem\" OUT2=$OUT1$sep$rem # This command generates a list of individuals with the status ?PROBLEM?. grep \"PROBLEM\" plink.sexcheck| awk '{print$1,$2}'> sex_discrepancy.txt plink --bfile $OUT1 --remove sex_discrepancy.txt --make-bed --out $OUT2","title":"Check for Sex Discrepancies"},{"location":"QC/#limit-data-to-autosomal-snps-only","text":"We wll generate a txt file with all the SNPS on the autosomes so that we can remove all SNPS that are on the sex chromosomes or in mitochondrial DND. BIM=\".bim\" AUTOSOME=\"autosome\" OUT3=$OUT2$sep$AUTOSOME awk '{ if ($1 >= 1 && $1 <= 23) print $2 }' $OUT2$BIM > snp_1_22.txt plink --bfile $OUT2 --extract snp_1_22.txt --make-bed --out $OUT3","title":"Limit data to autosomal SNPs only"},{"location":"QC/#perform-maf-check-and-filter-by-maf-threshold","text":"plink --bfile $OUT2 --freq --out MAF_check Performed in R maf_freq <- read.table(\"MAF_check.frq\", header =TRUE, as.is=T) pdf(\"MAF_distribution.pdf\") hist(maf_freq[,5],main = \"MAF distribution\", xlab = \"MAF\") dev.off() Now we want to filter out any SNPS with a MAF<0.05 for a small data set or 0.1 for a larger data set. TAG_MAF=\"maf\" OUT3=$OUT2$sep$TAG_MAF MAF=0.05 plink --bfile $OUT2 --maf $MAF --make-bed --out $OUT3","title":"Perform MAF check and filter by MAF Threshold"},{"location":"QC/#view-heterozygosity-distribution-and-remove-outliers","text":"Generate a pruned subset of SNPs that are in approximate linkage equilibrium. plink --bfile $OUT3 --indep-pairwise 50 5 0.5 Compute method-of-moments F coefficient estimates The --het flag in Plink computes observed and expected autosomal homozygous genotype counts for each sample, and reports method-of-moments F coefficient estimates (i.e. ( - ) / ( - )) to R_check.het. plink --bfile $OUT3 --extract plink.prune.in --het --out R_check Plot of the heterozygosity rate distribution generated in R het <- read.table(\"R_check.het\", head=TRUE) pdf(\"heterozygosity.pdf\") het$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\" hist(het$HET_RATE, xlab=\"Heterozygosity Rate\", ylab=\"Frequency\", main= \"Heterozygosity Rate\") dev.off() list of individuals who deviate more than 3 standard deviations from the heterozygosity rate mean generated in R het <- read.table(\"R_check.het\", head=TRUE) het$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\" het_fail = subset(het, (het$HET_RATE < mean(het$HET_RATE)-3*sd(het$HET_RATE)) | (het$HET_RATE > mean(het$HET_RATE)+3*sd(het$HET_RATE))); het_fail$HET_DST = (het_fail$HET_RATE-mean(het$HET_RATE))/sd(het$HET_RATE); write.table(het_fail, \"fail-het-qc.txt\", row.names=FALSE) The command above generates the fail-het-qc.txt file and the command below saves the first two rows to a new file named het_fail_ind.txt sed 's/\"// g' fail-het-qc.txt | awk '{print$1, $2}' > het_fail_ind.txt remove individuals that are heterozygous outliers HET=\"het_fix\" OUT4=$OUT3$sep$HET plink --bfile $OUT3 --remove het_fail_ind.txt --make-bed --out $OUT4","title":"View heterozygosity distribution and remove outliers"},{"location":"QC/#transfer-files-to-use-for-population-stratification","text":"rename files and copy to population stratification folder mkdir 2_Population_stratification bed=\".bed\" fam=\".fam\" bim=\".bim\" mv $OUT4$bed ./qcout.bed mv $OUT4$bim ./qcout.bim mv $OUT4$fam ./qcout.fam cp qcout* 2_Population_stratification cp plink.prune.in 2_Population_stratification change directory into population stratification folder cd 2_Population_stratification","title":"Transfer files to use for population stratification"},{"location":"cal_prs/","text":"Calculating and Analysing PRS \u00b6 Background \u00b6 In this section of the tutorial you will use four different software programs to compute PRS from the base and target data that you QC'ed in the previous two sections. The programs are PLINK PRSice-2 LDPred-2 lassosum","title":"3. Association Analyses"},{"location":"cal_prs/#calculating-and-analysing-prs","text":"","title":"Calculating and Analysing PRS"},{"location":"cal_prs/#background","text":"In this section of the tutorial you will use four different software programs to compute PRS from the base and target data that you QC'ed in the previous two sections. The programs are PLINK PRSice-2 LDPred-2 lassosum","title":"Background"},{"location":"lassosum/","text":"Background \u00b6 lassosum is one of the dedicated PRS programs which is an R package that uses penalised regression (LASSO) in its approach to PRS calculation. Installing lassosum \u00b6 Note The script used here is based on lassosum version 0.4.4 Note For more details, please refer to lassosum's homepage You can install lassosum and its dependencies in R with the following command: install.packages(c(\"devtools\",\"RcppArmadillo\", \"data.table\", \"Matrix\"), dependencies=TRUE) library(devtools) install_github(\"tshmak/lassosum\") Required Data \u00b6 Again, we assume that we have the following files (or you can download it from here ): File Name Description Height.QC.gz The post-QCed summary statistic EUR.QC.bed The genotype file after performing some basic filtering EUR.QC.bim This file contains the SNPs that passed the basic filtering EUR.QC.fam This file contains the samples that passed the basic filtering EUR.height This file contains the phenotype of the samples EUR.cov This file contains the covariates of the samples EUR.eigenvec This file contains the PCs of the samples Running PRS analysis \u00b6 We can run lassosum as follows: library(lassosum) # Prefer to work with data.table as it speeds up file reading library(data.table) library(methods) library(magrittr) # For multi-threading, you can use the parallel package and # invoke cl which is then passed to lassosum.pipeline library(parallel) # This will invoke 2 threads. cl <- makeCluster(2) sum.stat <- \"Height.QC.gz\" bfile <- \"EUR.QC\" # Read in and process the covariates covariate <- fread(\"EUR.cov\") pcs <- fread(\"EUR.eigenvec\") %>% setnames(., colnames(.), c(\"FID\",\"IID\", paste0(\"PC\",1:6))) # Need as.data.frame here as lassosum doesn't handle data.table # covariates very well cov <- merge(covariate, pcs) # We will need the EUR.hg19 file provided by lassosum # which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome. ld.file <- \"EUR.hg19\" # output prefix prefix <- \"EUR\" # Read in the target phenotype file target.pheno <- fread(\"EUR.height\")[,c(\"FID\", \"IID\", \"Height\")] # Read in the summary statistics ss <- fread(sum.stat) # Remove P-value = 0, which causes problem in the transformation ss <- ss[!P == 0] # Transform the P-values into correlation cor <- p2cor(p = ss$P, n = ss$N, sign = log(ss$OR) ) fam <- fread(paste0(bfile, \".fam\")) fam[,ID:=do.call(paste, c(.SD, sep=\":\")),.SDcols=c(1:2)] # Run the lassosum pipeline # The cluster parameter is used for multi-threading # You can ignore that if you do not wish to perform multi-threaded processing out <- lassosum.pipeline( cor = cor, chr = ss$CHR, pos = ss$BP, A1 = ss$A1, A2 = ss$A2, ref.bfile = bfile, test.bfile = bfile, LDblocks = ld.file, cluster=cl ) # Store the R2 results target.res <- validate(out, pheno = target.pheno, covar=cov) # Get the maximum R2 r2 <- max(target.res$validation.table$value)^2 How much phenotypic variation does the \"best-fit\" PRS explain? 0.2395471","title":"Background"},{"location":"lassosum/#background","text":"lassosum is one of the dedicated PRS programs which is an R package that uses penalised regression (LASSO) in its approach to PRS calculation.","title":"Background"},{"location":"lassosum/#installing-lassosum","text":"Note The script used here is based on lassosum version 0.4.4 Note For more details, please refer to lassosum's homepage You can install lassosum and its dependencies in R with the following command: install.packages(c(\"devtools\",\"RcppArmadillo\", \"data.table\", \"Matrix\"), dependencies=TRUE) library(devtools) install_github(\"tshmak/lassosum\")","title":"Installing lassosum"},{"location":"lassosum/#required-data","text":"Again, we assume that we have the following files (or you can download it from here ): File Name Description Height.QC.gz The post-QCed summary statistic EUR.QC.bed The genotype file after performing some basic filtering EUR.QC.bim This file contains the SNPs that passed the basic filtering EUR.QC.fam This file contains the samples that passed the basic filtering EUR.height This file contains the phenotype of the samples EUR.cov This file contains the covariates of the samples EUR.eigenvec This file contains the PCs of the samples","title":"Required Data"},{"location":"lassosum/#running-prs-analysis","text":"We can run lassosum as follows: library(lassosum) # Prefer to work with data.table as it speeds up file reading library(data.table) library(methods) library(magrittr) # For multi-threading, you can use the parallel package and # invoke cl which is then passed to lassosum.pipeline library(parallel) # This will invoke 2 threads. cl <- makeCluster(2) sum.stat <- \"Height.QC.gz\" bfile <- \"EUR.QC\" # Read in and process the covariates covariate <- fread(\"EUR.cov\") pcs <- fread(\"EUR.eigenvec\") %>% setnames(., colnames(.), c(\"FID\",\"IID\", paste0(\"PC\",1:6))) # Need as.data.frame here as lassosum doesn't handle data.table # covariates very well cov <- merge(covariate, pcs) # We will need the EUR.hg19 file provided by lassosum # which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome. ld.file <- \"EUR.hg19\" # output prefix prefix <- \"EUR\" # Read in the target phenotype file target.pheno <- fread(\"EUR.height\")[,c(\"FID\", \"IID\", \"Height\")] # Read in the summary statistics ss <- fread(sum.stat) # Remove P-value = 0, which causes problem in the transformation ss <- ss[!P == 0] # Transform the P-values into correlation cor <- p2cor(p = ss$P, n = ss$N, sign = log(ss$OR) ) fam <- fread(paste0(bfile, \".fam\")) fam[,ID:=do.call(paste, c(.SD, sep=\":\")),.SDcols=c(1:2)] # Run the lassosum pipeline # The cluster parameter is used for multi-threading # You can ignore that if you do not wish to perform multi-threaded processing out <- lassosum.pipeline( cor = cor, chr = ss$CHR, pos = ss$BP, A1 = ss$A1, A2 = ss$A2, ref.bfile = bfile, test.bfile = bfile, LDblocks = ld.file, cluster=cl ) # Store the R2 results target.res <- validate(out, pheno = target.pheno, covar=cov) # Get the maximum R2 r2 <- max(target.res$validation.table$value)^2 How much phenotypic variation does the \"best-fit\" PRS explain? 0.2395471","title":"Running PRS analysis"},{"location":"liftover/","text":"Background \u00b6 LDpred-2 is one of the dedicated PRS programs which is an R package that uses a Bayesian approach to polygenic risk scoring. Installing LDpred-2 \u00b6 Note The script used here is based on LDpred 2 implemented under bigsnpr version 1.4.7 Note For more details, please refer to LDpred 2's homepage You can install LDpred and its dependencies in R with the following command: install.packages(\"remotes\") library(remotes) remotes::install_github(\"https://github.com/privefl/bigsnpr.git\") Note For mac users, you might need to follow the guide here to be able to install LDpred2 Required Data \u00b6 We assume that you have the following files (or you can download it from here ): File Name Description Height.QC.gz The post-QCed summary statistic EUR.QC.bed The genotype file after performing some basic filtering EUR.QC.bim This file contains the SNPs that passed the basic filtering EUR.QC.fam This file contains the samples that passed the basic filtering EUR.height This file contains the phenotype of the samples EUR.cov This file contains the covariates of the samples EUR.eigenvec This file contains the PCs of the samples Warning While we do provide a rough guide on how to perform LDpred on bed files separated into individual chromosomes, this script is untested and extra caution is required 0. Prepare workspace \u00b6 On some server, you might need to first use the following code in order to run LDpred with multi-thread prepare workspace and load bigsnpr library(bigsnpr) options(bigstatsr.check.parallel.blas = FALSE) options(default.nproc.blas = NULL) 1. Read in the phenotype and covariate files \u00b6 read in phenotype and covariates library(data.table) library(magrittr) phenotype <- fread(\"EUR.height\") covariate <- fread(\"EUR.cov\") pcs <- fread(\"EUR.eigenvec\") # rename columns colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6)) # generate required table pheno <- merge(phenotype, covariate) %>% merge(., pcs) 2. Obtain HapMap3 SNPs \u00b6 LDpred2 authors recommend restricting the analysis to only the HapMap3 SNPs load HapMap3 SNPs info <- readRDS(url(\"https://github.com/privefl/bigsnpr/raw/master/data-raw/hm3_variants.rds\")) 3. Load and transform the summary statistic file \u00b6 Load summary statistic file # Read in the summary statistic file sumstats <- bigreadr::fread2(\"Height.QC.gz\") # LDpred 2 require the header to follow the exact naming names(sumstats) <- c(\"chr\", \"pos\", \"rsid\", \"a1\", \"a0\", \"n_eff\", \"beta_se\", \"p\", \"OR\", \"INFO\", \"MAF\") # Transform the OR into log(OR) sumstats$beta <- log(sumstats$OR) # Filter out hapmap SNPs sumstats <- sumstats[sumstats$rsid%in% info$rsid,] Warning Here, we know the exact ordering of the summary statistics file. However, in many cases, the ordering of the summary statistics differ, thus one must rename the columns according to their actual ordering 3. Calculate the LD matrix \u00b6 Genome Wide bed file # Get maximum amount of cores NCORES <- nb_cores() # Open a temporary file tmp <- tempfile(tmpdir = \"tmp-data\") on.exit(file.remove(paste0(tmp, \".sbk\")), add = TRUE) # Initialize variables for storing the LD score and LD matrix corr <- NULL ld <- NULL # We want to know the ordering of samples in the bed file fam.order <- NULL # preprocess the bed file (only need to do once for each data set) snp_readBed(\"EUR.QC.bed\") # now attach the genotype object obj.bigSNP <- snp_attach(\"EUR.QC.rds\") # extract the SNP information from the genotype map <- obj.bigSNP$map[-3] names(map) <- c(\"chr\", \"rsid\", \"pos\", \"a1\", \"a0\") # perform SNP matching info_snp <- snp_match(sumstats, map) # Assign the genotype to a variable for easier downstream analysis genotype <- obj.bigSNP$genotypes # Rename the data structures CHR <- map$chr POS <- map$pos # get the CM information from 1000 Genome # will download the 1000G file to the current directory (\".\") POS2 <- snp_asGeneticPos(CHR, POS, dir = \".\") # calculate LD for (chr in 1:22) { # Extract SNPs that are included in the chromosome ind.chr <- which(info_snp$chr == chr) ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr] # Calculate the LD corr0 <- snp_cor( genotype, ind.col = ind.chr2, ncores = NCORES, infos.pos = POS2[ind.chr2], size = 3 / 1000 ) if (chr == 1) { ld <- Matrix::colSums(corr0^2) corr <- as_SFBM(corr0, tmp) } else { ld <- c(ld, Matrix::colSums(corr0^2)) corr$add_columns(corr0, nrow(corr)) } } # We assume the fam order is the same across different chromosomes fam.order <- as.data.table(obj.bigSNP$fam) # Rename fam order setnames(fam.order, c(\"family.ID\", \"sample.ID\"), c(\"FID\", \"IID\")) Chromosome separated bed files # Get maximum amount of cores NCORES <- nb_cores() # Open a temporary file tmp <- tempfile(tmpdir = \"tmp-data\") on.exit(file.remove(paste0(tmp, \".sbk\")), add = TRUE) # Initialize variables for storing the LD score and LD matrix corr <- NULL ld <- NULL # We want to know the ordering of samples in the bed file info_snp <- NULL fam.order <- NULL for (chr in 1:22) { # preprocess the bed file (only need to do once for each data set) # Assuming the file naming is EUR_chr#.bed snp_readBed(paste0(\"EUR_chr\",chr,\".bed\")) # now attach the genotype object obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\".rds\")) # extract the SNP information from the genotype map <- obj.bigSNP$map[-3] names(map) <- c(\"chr\", \"rsid\", \"pos\", \"a1\", \"a0\") # perform SNP matching tmp_snp <- snp_match(sumstats[sumstats$chr==chr,], map) info_snp <- rbind(info_snp, tmp_snp) # Assign the genotype to a variable for easier downstream analysis genotype <- obj.bigSNP$genotypes # Rename the data structures CHR <- map$chr POS <- map$pos # get the CM information from 1000 Genome # will download the 1000G file to the current directory (\".\") POS2 <- snp_asGeneticPos(CHR, POS, dir = \".\") # calculate LD # Extract SNPs that are included in the chromosome ind.chr <- which(tmp_snp$chr == chr) ind.chr2 <- tmp_snp$`_NUM_ID_`[ind.chr] # Calculate the LD corr0 <- snp_cor( genotype, ind.col = ind.chr2, ncores = NCORES, infos.pos = POS2[ind.chr2], size = 3 / 1000 ) if (chr == 1) { ld <- Matrix::colSums(corr0^2) corr <- as_SFBM(corr0, tmp) } else { ld <- c(ld, Matrix::colSums(corr0^2)) corr$add_columns(corr0, nrow(corr)) } # We assume the fam order is the same across different chromosomes if(is.null(fam.order)){ fam.order <- as.data.table(obj.bigSNP$fam) } } # Rename fam order setnames(fam.order, c(\"family.ID\", \"sample.ID\"), c(\"FID\", \"IID\")) 4. Perform LD score regression \u00b6 Perform LD score regression df_beta <- info_snp[,c(\"beta\", \"beta_se\", \"n_eff\", \"_NUM_ID_\")] ldsc <- snp_ldsc( ld, length(ld), chi2 = (df_beta$beta / df_beta$beta_se)^2, sample_size = df_beta$n_eff, blocks = NULL) h2_est <- ldsc[[\"h2\"]] 5. Calculate the null R2 \u00b6 Calculate the null R2 (quantitative trait) # Reformat the phenotype file such that y is of the same order as the # sample ordering in the genotype file y <- pheno[fam.order, on = c(\"FID\", \"IID\")] # Calculate the null R2 # use glm for binary trait # (will also need the fmsb package to calculate the pseudo R2) null.model <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~Sex+\", .) %>% as.formula %>% lm(., data = y) %>% summary null.r2 <- null.model$r.squared Calculate the null R2 (binary trait) library(fmsb) # Reformat the phenotype file such that y is of the same order as the # sample ordering in the genotype file y <- pheno[fam.order, on = c(\"FID\", \"IID\")] # Calculate the null R2 # use glm for binary trait # (will also need the fmsb package to calculate the pseudo R2) null.model <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~Sex+\", .) %>% as.formula %>% glm(., data = y, family=binomial) %>% summary null.r2 <- fmsb::NagelkerkeR2(null.model) Important Scripts for binary trait analysis only serve as a reference as we have not simulate any binary traits. In addition, Nagelkerke \\(R^2\\) is biased when there are ascertainment of samples. For more information, please refer to this paper infinitesimal model beta_inf <- snp_ldpred2_inf(corr, df_beta, h2 = h2_est) grid model # Prepare data for grid model p_seq <- signif(seq_log(1e-4, 1, length.out = 17), 2) h2_seq <- round(h2_est * c(0.7, 1, 1.4), 4) grid.param <- expand.grid(p = p_seq, h2 = h2_seq, sparse = c(FALSE, TRUE)) # Get adjusted beta from grid model beta_grid <- snp_ldpred2_grid(corr, df_beta, grid.param, ncores = NCORES) auto model # Get adjusted beta from the auto model multi_auto <- snp_ldpred2_auto( corr, df_beta, h2_init = h2_est, vec_p_init = seq_log(1e-4, 0.9, length.out = NCORES), ncores = NCORES ) beta_auto <- sapply(multi_auto, function(auto) auto$beta_est) 7. Obtain model PRS \u00b6 Using Genome wide bed file \u00b6 infinitesimal model if(is.null(obj.bigSNP)){ obj.bigSNP <- snp_attach(\"EUR.QC.rds\") } genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) pred_inf <- big_prodVec( genotype, beta_inf, ind.row = ind.test, ind.col = info_snp$`_NUM_ID_`) grid model if(is.null(obj.bigSNP)){ obj.bigSNP <- snp_attach(\"EUR.QC.rds\") } genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) pred_grid <- big_prodMat( genotype, beta_grid, ind.col = info_snp$`_NUM_ID_`) auto model if(is.null(obj.bigSNP)){ obj.bigSNP <- snp_attach(\"EUR.QC.rds\") } genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) pred_auto <- big_prodMat(genotype, beta_auto, ind.row = ind.test, ind.col = info_snp$`_NUM_ID_`) # scale the PRS generated from AUTO pred_scaled <- apply(pred_auto, 2, sd) final_beta_auto <- rowMeans(beta_auto[, abs(pred_scaled - median(pred_scaled)) < 3 * mad(pred_scaled)]) pred_auto <- big_prodVec(genotype, final_beta_auto, ind.row = ind.test, ind.col = info_snp$`_NUM_ID_`) Using chromosome separated bed files \u00b6 infinitesimal model pred_inf <- NULL for(chr in 1:22){ obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\".rds\")) genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) # Extract SNPs in this chromosome chr.idx <- which(info_snp$chr == chr) ind.chr <- info_snp$`_NUM_ID_`[chr.idx] tmp <- big_prodVec(genotype, beta_inf[chr.idx], ind.row = ind.test, ind.col = ind.chr) if(is.null(pred_inf)){ pred_inf <- tmp }else{ pred_inf <- pred_inf + tmp } } grid model pred_grid <- NULL for(chr in 1:22){ obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\"_.rds\")) genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) # Extract SNPs in this chromosome chr.idx <- which(info_snp$chr == chr) ind.chr <- info_snp$`_NUM_ID_`[chr.idx] tmp <- big_prodMat( genotype, beta_grid[chr.idx], ind.col = ind.chr) if(is.null(pred_grid)){ pred_grid <- tmp }else{ pred_grid <- pred_grid + tmp } } auto model pred_auto <- NULL for(chr in 1:22){ obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\"_.rds\")) genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) # Extract SNPs in this chromosome chr.idx <- which(info_snp$chr == chr) ind.chr <- info_snp$`_NUM_ID_`[chr.idx] tmp <- big_prodMat(genotype, beta_auto[chr.idx], ind.row = ind.test, ind.col = ind.chr) # scale the PRS generated from AUTO pred_scaled <- apply(tmp, 2, sd) final_beta_auto <- rowMeans(beta_auto[chr.idx, abs(pred_scaled - median(pred_scaled)) < 3 * mad(pred_scaled)]) tmp <- big_prodVec(genotype, final_beta_auto, ind.row = ind.test, ind.col = ind.chr) if(is.null(pred_auto)){ pred_auto <- tmp }else{ pred_auto <- pred_auto + tmp } } 8. Get the final performance of the LDpred models \u00b6 infinitesimal model reg.formula <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~PRS+Sex+\", .) %>% as.formula reg.dat <- y reg.dat$PRS <- pred_inf inf.model <- lm(reg.formula, dat=reg.dat) %>% summary (result <- data.table( infinitesimal = inf.model$r.squared - null.r2, null = null.r2 )) grid model reg.formula <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~PRS+Sex+\", .) %>% as.formula reg.dat <- y max.r2 <- 0 for(i in 1:ncol(pred_grid)){ reg.dat$PRS <- pred_grid[,i] grid.model <- lm(reg.formula, dat=reg.dat) %>% summary if(max.r2 < grid.model$r.squared){ max.r2 <- grid.model$r.squared } } (result <- data.table( grid = max.r2 - null.r2, null = null.r2 )) auto model reg.formula <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~PRS+Sex+\", .) %>% as.formula reg.dat <- y reg.dat$PRS <- pred_auto auto.model <- lm(reg.formula, dat=reg.dat) %>% summary (result <- data.table( auto = auto.model$r.squared - null.r2, null = null.r2 )) How much phenotypic variation does the PRS from each model explain? Infinitesimal = 0.0100 Grid Model = 0.00180 Auto Model = 0.171","title":"liftover"},{"location":"liftover/#background","text":"LDpred-2 is one of the dedicated PRS programs which is an R package that uses a Bayesian approach to polygenic risk scoring.","title":"Background"},{"location":"liftover/#installing-ldpred-2","text":"Note The script used here is based on LDpred 2 implemented under bigsnpr version 1.4.7 Note For more details, please refer to LDpred 2's homepage You can install LDpred and its dependencies in R with the following command: install.packages(\"remotes\") library(remotes) remotes::install_github(\"https://github.com/privefl/bigsnpr.git\") Note For mac users, you might need to follow the guide here to be able to install LDpred2","title":"Installing LDpred-2"},{"location":"liftover/#required-data","text":"We assume that you have the following files (or you can download it from here ): File Name Description Height.QC.gz The post-QCed summary statistic EUR.QC.bed The genotype file after performing some basic filtering EUR.QC.bim This file contains the SNPs that passed the basic filtering EUR.QC.fam This file contains the samples that passed the basic filtering EUR.height This file contains the phenotype of the samples EUR.cov This file contains the covariates of the samples EUR.eigenvec This file contains the PCs of the samples Warning While we do provide a rough guide on how to perform LDpred on bed files separated into individual chromosomes, this script is untested and extra caution is required","title":"Required Data"},{"location":"liftover/#0-prepare-workspace","text":"On some server, you might need to first use the following code in order to run LDpred with multi-thread prepare workspace and load bigsnpr library(bigsnpr) options(bigstatsr.check.parallel.blas = FALSE) options(default.nproc.blas = NULL)","title":"0. Prepare workspace"},{"location":"liftover/#1-read-in-the-phenotype-and-covariate-files","text":"read in phenotype and covariates library(data.table) library(magrittr) phenotype <- fread(\"EUR.height\") covariate <- fread(\"EUR.cov\") pcs <- fread(\"EUR.eigenvec\") # rename columns colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6)) # generate required table pheno <- merge(phenotype, covariate) %>% merge(., pcs)","title":"1. Read in the phenotype and covariate files"},{"location":"liftover/#2-obtain-hapmap3-snps","text":"LDpred2 authors recommend restricting the analysis to only the HapMap3 SNPs load HapMap3 SNPs info <- readRDS(url(\"https://github.com/privefl/bigsnpr/raw/master/data-raw/hm3_variants.rds\"))","title":"2. Obtain HapMap3 SNPs"},{"location":"liftover/#3-load-and-transform-the-summary-statistic-file","text":"Load summary statistic file # Read in the summary statistic file sumstats <- bigreadr::fread2(\"Height.QC.gz\") # LDpred 2 require the header to follow the exact naming names(sumstats) <- c(\"chr\", \"pos\", \"rsid\", \"a1\", \"a0\", \"n_eff\", \"beta_se\", \"p\", \"OR\", \"INFO\", \"MAF\") # Transform the OR into log(OR) sumstats$beta <- log(sumstats$OR) # Filter out hapmap SNPs sumstats <- sumstats[sumstats$rsid%in% info$rsid,] Warning Here, we know the exact ordering of the summary statistics file. However, in many cases, the ordering of the summary statistics differ, thus one must rename the columns according to their actual ordering","title":"3. Load and transform the summary statistic file"},{"location":"liftover/#3-calculate-the-ld-matrix","text":"Genome Wide bed file # Get maximum amount of cores NCORES <- nb_cores() # Open a temporary file tmp <- tempfile(tmpdir = \"tmp-data\") on.exit(file.remove(paste0(tmp, \".sbk\")), add = TRUE) # Initialize variables for storing the LD score and LD matrix corr <- NULL ld <- NULL # We want to know the ordering of samples in the bed file fam.order <- NULL # preprocess the bed file (only need to do once for each data set) snp_readBed(\"EUR.QC.bed\") # now attach the genotype object obj.bigSNP <- snp_attach(\"EUR.QC.rds\") # extract the SNP information from the genotype map <- obj.bigSNP$map[-3] names(map) <- c(\"chr\", \"rsid\", \"pos\", \"a1\", \"a0\") # perform SNP matching info_snp <- snp_match(sumstats, map) # Assign the genotype to a variable for easier downstream analysis genotype <- obj.bigSNP$genotypes # Rename the data structures CHR <- map$chr POS <- map$pos # get the CM information from 1000 Genome # will download the 1000G file to the current directory (\".\") POS2 <- snp_asGeneticPos(CHR, POS, dir = \".\") # calculate LD for (chr in 1:22) { # Extract SNPs that are included in the chromosome ind.chr <- which(info_snp$chr == chr) ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr] # Calculate the LD corr0 <- snp_cor( genotype, ind.col = ind.chr2, ncores = NCORES, infos.pos = POS2[ind.chr2], size = 3 / 1000 ) if (chr == 1) { ld <- Matrix::colSums(corr0^2) corr <- as_SFBM(corr0, tmp) } else { ld <- c(ld, Matrix::colSums(corr0^2)) corr$add_columns(corr0, nrow(corr)) } } # We assume the fam order is the same across different chromosomes fam.order <- as.data.table(obj.bigSNP$fam) # Rename fam order setnames(fam.order, c(\"family.ID\", \"sample.ID\"), c(\"FID\", \"IID\")) Chromosome separated bed files # Get maximum amount of cores NCORES <- nb_cores() # Open a temporary file tmp <- tempfile(tmpdir = \"tmp-data\") on.exit(file.remove(paste0(tmp, \".sbk\")), add = TRUE) # Initialize variables for storing the LD score and LD matrix corr <- NULL ld <- NULL # We want to know the ordering of samples in the bed file info_snp <- NULL fam.order <- NULL for (chr in 1:22) { # preprocess the bed file (only need to do once for each data set) # Assuming the file naming is EUR_chr#.bed snp_readBed(paste0(\"EUR_chr\",chr,\".bed\")) # now attach the genotype object obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\".rds\")) # extract the SNP information from the genotype map <- obj.bigSNP$map[-3] names(map) <- c(\"chr\", \"rsid\", \"pos\", \"a1\", \"a0\") # perform SNP matching tmp_snp <- snp_match(sumstats[sumstats$chr==chr,], map) info_snp <- rbind(info_snp, tmp_snp) # Assign the genotype to a variable for easier downstream analysis genotype <- obj.bigSNP$genotypes # Rename the data structures CHR <- map$chr POS <- map$pos # get the CM information from 1000 Genome # will download the 1000G file to the current directory (\".\") POS2 <- snp_asGeneticPos(CHR, POS, dir = \".\") # calculate LD # Extract SNPs that are included in the chromosome ind.chr <- which(tmp_snp$chr == chr) ind.chr2 <- tmp_snp$`_NUM_ID_`[ind.chr] # Calculate the LD corr0 <- snp_cor( genotype, ind.col = ind.chr2, ncores = NCORES, infos.pos = POS2[ind.chr2], size = 3 / 1000 ) if (chr == 1) { ld <- Matrix::colSums(corr0^2) corr <- as_SFBM(corr0, tmp) } else { ld <- c(ld, Matrix::colSums(corr0^2)) corr$add_columns(corr0, nrow(corr)) } # We assume the fam order is the same across different chromosomes if(is.null(fam.order)){ fam.order <- as.data.table(obj.bigSNP$fam) } } # Rename fam order setnames(fam.order, c(\"family.ID\", \"sample.ID\"), c(\"FID\", \"IID\"))","title":"3. Calculate the LD matrix"},{"location":"liftover/#4-perform-ld-score-regression","text":"Perform LD score regression df_beta <- info_snp[,c(\"beta\", \"beta_se\", \"n_eff\", \"_NUM_ID_\")] ldsc <- snp_ldsc( ld, length(ld), chi2 = (df_beta$beta / df_beta$beta_se)^2, sample_size = df_beta$n_eff, blocks = NULL) h2_est <- ldsc[[\"h2\"]]","title":"4. Perform LD score regression"},{"location":"liftover/#5-calculate-the-null-r2","text":"Calculate the null R2 (quantitative trait) # Reformat the phenotype file such that y is of the same order as the # sample ordering in the genotype file y <- pheno[fam.order, on = c(\"FID\", \"IID\")] # Calculate the null R2 # use glm for binary trait # (will also need the fmsb package to calculate the pseudo R2) null.model <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~Sex+\", .) %>% as.formula %>% lm(., data = y) %>% summary null.r2 <- null.model$r.squared Calculate the null R2 (binary trait) library(fmsb) # Reformat the phenotype file such that y is of the same order as the # sample ordering in the genotype file y <- pheno[fam.order, on = c(\"FID\", \"IID\")] # Calculate the null R2 # use glm for binary trait # (will also need the fmsb package to calculate the pseudo R2) null.model <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~Sex+\", .) %>% as.formula %>% glm(., data = y, family=binomial) %>% summary null.r2 <- fmsb::NagelkerkeR2(null.model) Important Scripts for binary trait analysis only serve as a reference as we have not simulate any binary traits. In addition, Nagelkerke \\(R^2\\) is biased when there are ascertainment of samples. For more information, please refer to this paper infinitesimal model beta_inf <- snp_ldpred2_inf(corr, df_beta, h2 = h2_est) grid model # Prepare data for grid model p_seq <- signif(seq_log(1e-4, 1, length.out = 17), 2) h2_seq <- round(h2_est * c(0.7, 1, 1.4), 4) grid.param <- expand.grid(p = p_seq, h2 = h2_seq, sparse = c(FALSE, TRUE)) # Get adjusted beta from grid model beta_grid <- snp_ldpred2_grid(corr, df_beta, grid.param, ncores = NCORES) auto model # Get adjusted beta from the auto model multi_auto <- snp_ldpred2_auto( corr, df_beta, h2_init = h2_est, vec_p_init = seq_log(1e-4, 0.9, length.out = NCORES), ncores = NCORES ) beta_auto <- sapply(multi_auto, function(auto) auto$beta_est)","title":"5. Calculate the null R2"},{"location":"liftover/#7-obtain-model-prs","text":"","title":"7. Obtain model PRS"},{"location":"liftover/#using-genome-wide-bed-file","text":"infinitesimal model if(is.null(obj.bigSNP)){ obj.bigSNP <- snp_attach(\"EUR.QC.rds\") } genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) pred_inf <- big_prodVec( genotype, beta_inf, ind.row = ind.test, ind.col = info_snp$`_NUM_ID_`) grid model if(is.null(obj.bigSNP)){ obj.bigSNP <- snp_attach(\"EUR.QC.rds\") } genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) pred_grid <- big_prodMat( genotype, beta_grid, ind.col = info_snp$`_NUM_ID_`) auto model if(is.null(obj.bigSNP)){ obj.bigSNP <- snp_attach(\"EUR.QC.rds\") } genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) pred_auto <- big_prodMat(genotype, beta_auto, ind.row = ind.test, ind.col = info_snp$`_NUM_ID_`) # scale the PRS generated from AUTO pred_scaled <- apply(pred_auto, 2, sd) final_beta_auto <- rowMeans(beta_auto[, abs(pred_scaled - median(pred_scaled)) < 3 * mad(pred_scaled)]) pred_auto <- big_prodVec(genotype, final_beta_auto, ind.row = ind.test, ind.col = info_snp$`_NUM_ID_`)","title":"Using Genome wide bed file"},{"location":"liftover/#using-chromosome-separated-bed-files","text":"infinitesimal model pred_inf <- NULL for(chr in 1:22){ obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\".rds\")) genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) # Extract SNPs in this chromosome chr.idx <- which(info_snp$chr == chr) ind.chr <- info_snp$`_NUM_ID_`[chr.idx] tmp <- big_prodVec(genotype, beta_inf[chr.idx], ind.row = ind.test, ind.col = ind.chr) if(is.null(pred_inf)){ pred_inf <- tmp }else{ pred_inf <- pred_inf + tmp } } grid model pred_grid <- NULL for(chr in 1:22){ obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\"_.rds\")) genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) # Extract SNPs in this chromosome chr.idx <- which(info_snp$chr == chr) ind.chr <- info_snp$`_NUM_ID_`[chr.idx] tmp <- big_prodMat( genotype, beta_grid[chr.idx], ind.col = ind.chr) if(is.null(pred_grid)){ pred_grid <- tmp }else{ pred_grid <- pred_grid + tmp } } auto model pred_auto <- NULL for(chr in 1:22){ obj.bigSNP <- snp_attach(paste0(\"EUR_chr\",chr,\"_.rds\")) genotype <- obj.bigSNP$genotypes # calculate PRS for all samples ind.test <- 1:nrow(genotype) # Extract SNPs in this chromosome chr.idx <- which(info_snp$chr == chr) ind.chr <- info_snp$`_NUM_ID_`[chr.idx] tmp <- big_prodMat(genotype, beta_auto[chr.idx], ind.row = ind.test, ind.col = ind.chr) # scale the PRS generated from AUTO pred_scaled <- apply(tmp, 2, sd) final_beta_auto <- rowMeans(beta_auto[chr.idx, abs(pred_scaled - median(pred_scaled)) < 3 * mad(pred_scaled)]) tmp <- big_prodVec(genotype, final_beta_auto, ind.row = ind.test, ind.col = ind.chr) if(is.null(pred_auto)){ pred_auto <- tmp }else{ pred_auto <- pred_auto + tmp } }","title":"Using chromosome separated bed files"},{"location":"liftover/#8-get-the-final-performance-of-the-ldpred-models","text":"infinitesimal model reg.formula <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~PRS+Sex+\", .) %>% as.formula reg.dat <- y reg.dat$PRS <- pred_inf inf.model <- lm(reg.formula, dat=reg.dat) %>% summary (result <- data.table( infinitesimal = inf.model$r.squared - null.r2, null = null.r2 )) grid model reg.formula <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~PRS+Sex+\", .) %>% as.formula reg.dat <- y max.r2 <- 0 for(i in 1:ncol(pred_grid)){ reg.dat$PRS <- pred_grid[,i] grid.model <- lm(reg.formula, dat=reg.dat) %>% summary if(max.r2 < grid.model$r.squared){ max.r2 <- grid.model$r.squared } } (result <- data.table( grid = max.r2 - null.r2, null = null.r2 )) auto model reg.formula <- paste(\"PC\", 1:6, sep = \"\", collapse = \"+\") %>% paste0(\"Height~PRS+Sex+\", .) %>% as.formula reg.dat <- y reg.dat$PRS <- pred_auto auto.model <- lm(reg.formula, dat=reg.dat) %>% summary (result <- data.table( auto = auto.model$r.squared - null.r2, null = null.r2 )) How much phenotypic variation does the PRS from each model explain? Infinitesimal = 0.0100 Grid Model = 0.00180 Auto Model = 0.171","title":"8. Get the final performance of the LDpred models"},{"location":"plink/","text":"Background \u00b6 On this page, you will compute PRS using the popular genetic analyses tool plink - while plink is not a dedicated PRS software, you can perform every required steps of the C+T approach with plink . This multi-step process is a good way to learn the processes involved in computing PRS, which are typically performed automatically by PRS software. Required Data \u00b6 In the previous sections, we have generated the following files: File Name Description Height.QC.gz The post-QCed summary statistic EUR.QC.bed The genotype file after performing some basic filtering EUR.QC.bim This file contains the SNPs that passed the basic filtering EUR.QC.fam This file contains the samples that passed the basic filtering EUR.height This file contains the phenotype of the samples EUR.cov This file contains the covariates of the samples Update Effect Size \u00b6 When the effect size relates to disease risk and is thus given as an odds ratio (OR), rather than BETA (for continuous traits), then the PRS is computed as a product of ORs. To simplify this calculation, we take the natural logarithm of the OR so that the PRS can be computed using summation instead (which can be back-transformed afterwards). We can obtain the transformed summary statistics with R : Without data.table dat <- read.table(gzfile(\"Height.QC.gz\"), header=T) dat$BETA <- log(dat$OR) write.table(dat, \"Height.QC.Transformed\", quote=F, row.names=F) q() # exit R With data.table library(data.table) dat <- fread(\"Height.QC.gz\") fwrite(dat[,BETA:=log(OR)], \"Height.QC.Transformed\", sep=\"\\t\") q() # exit R Warning Due to rounding of values, using awk to log transform OR can lead to less accurate results. Therefore, we recommend performing the transformation in R or allow the PRS software to perform the transformation directly. Clumping \u00b6 Linkage disequilibrium, which corresponds to the correlation between the genotypes of genetic variants across the genome, makes identifying the contribution from causal independent genetic variants extremely challenging. One way of approximately capturing the right level of causal signal is to perform clumping, which removes SNPs in ways that only weakly correlated SNPs are retained but preferentially retaining the SNPs most associated with the phenotype under study. Clumping can be performed using the following command in plink : plink \\ --bfile EUR.QC \\ --clump-p1 1 \\ --clump-r2 0.1 \\ --clump-kb 250 \\ --clump Height.QC.Transformed \\ --clump-snp-field SNP \\ --clump-field P \\ --out EUR Each of the new parameters corresponds to the following Parameter Value Description clump-p1 1 P-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping clump-r2 0.1 SNPs having \\(r^2\\) higher than 0.1 with the index SNPs will be removed clump-kb 250 SNPs within 250k of the index SNP are considered for clumping clump Height.QC.Transformed Base data (summary statistic) file containing the P-value information clump-snp-field SNP Specifies that the column SNP contains the SNP IDs clump-field P Specifies that the column P contains the P-value information A more detailed description of the clumping process can be found here Note The \\(r^2\\) values computed by --clump are based on maximum likelihood haplotype frequency estimates This will generate EUR.clumped , containing the index SNPs after clumping is performed. We can extract the index SNP ID by performing the following command: awk 'NR!=1{print $3}' EUR.clumped > EUR.valid.snp $3 because the third column contains the SNP ID Note If your target data are small (e.g. N < 500) then you can use the 1000 Genomes Project samples for the LD calculation. Make sure to use the population that most closely reflects represents the base sample. Generate PRS \u00b6 plink provides a convenient function --score and --q-score-range for calculating polygenic scores. We will need three files: The base data file: Height.QC.Transformed A file containing SNP IDs and their corresponding P-values ( $3 because SNP ID is located in the third column; $8 because the P-value is located in the eighth column) awk '{print $3,$8}' Height.QC.Transformed > SNP.pvalue A file containing the different P-value thresholds for inclusion of SNPs in the PRS. Here calculate PRS corresponding to a few thresholds for illustration purposes: echo \"0.001 0 0.001\" > range_list echo \"0.05 0 0.05\" >> range_list echo \"0.1 0 0.1\" >> range_list echo \"0.2 0 0.2\" >> range_list echo \"0.3 0 0.3\" >> range_list echo \"0.4 0 0.4\" >> range_list echo \"0.5 0 0.5\" >> range_list The format of the range_list file should be as follows: Name of Threshold Lower bound Upper Bound Note The threshold boundaries are inclusive. For example, for the 0.05 threshold, we include all SNPs with P-value from 0 to 0.05 , including any SNPs with P-value equal to 0.05 . We can then calculate the PRS with the following plink command: plink \\ --bfile EUR.QC \\ --score Height.QC.Transformed 3 4 12 header \\ --q-score-range range_list SNP.pvalue \\ --extract EUR.valid.snp \\ --out EUR The meaning of the new parameters are as follows: Paramter Value Description score Height.QC.Transformed 3 4 12 header We read from the Height.QC.Transformed file, assuming that the 3 st column is the SNP ID; 4 th column is the effective allele information; the 12 th column is the effect size estimate; and that the file contains a header q-score-range range_list SNP.pvalue We want to calculate PRS based on the thresholds defined in range_list , where the threshold values (P-values) were stored in SNP.pvalue The above command and range_list will generate 7 files: EUR.0.5.profile EUR.0.4.profile EUR.0.3.profile EUR.0.2.profile EUR.0.1.profile EUR.0.05.profile EUR.0.001.profile Note The default formula for PRS calculation in PLINK is: \\[ PRS_j =\\frac{ \\sum_i^NS_i*G_{ij}}{P*M_j} \\] where the effect size of SNP \\(i\\) is \\(S_i\\) ; the number of effect alleles observed in sample \\(j\\) is \\(G_{ij}\\) ; the ploidy of the sample is \\(P\\) (is generally 2 for humans); the total number of SNPs included in the PRS is \\(N\\) ; and the number of non-missing SNPs observed in sample \\(j\\) is \\(M_j\\) . If the sample has a missing genotype for SNP \\(i\\) , then the population minor allele frequency multiplied by the ploidy ( \\(MAF_i*P\\) ) is used instead of \\(G_{ij}\\) . Accounting for Population Stratification \u00b6 Population structure is the principal source of confounding in GWAS and is usually accounted for by incorporating principal components (PCs) as covariates. We can incorporate PCs into our PRS analysis to account for population stratification. Again, we can calculate the PCs using plink : # First, we need to perform prunning plink \\ --bfile EUR.QC \\ --indep-pairwise 200 50 0.25 \\ --out EUR # Then we calculate the first 6 PCs plink \\ --bfile EUR.QC \\ --extract EUR.prune.in \\ --pca 6 \\ --out EUR Note One way to select the appropriate number of PCs is to perform GWAS on the phenotype under study with different numbers of PCs. LDSC analysis can then be performed on the set of GWAS summary statistics and the GWAS that used the number of PCs that gave an LDSC intercept closest to 1 should correspond to that for which population structure was most accurately controlled for. Here the PCs have been stored in the EUR.eigenvec file and can be used as covariates in the regression model to account for population stratification. Important If the base and target samples are collected from different worldwide populations then the results from the PRS analysis may be biased (see Section 3.4 of our papper). Finding the \"best-fit\" PRS \u00b6 The P-value threshold that provides the \"best-fit\" PRS under the C+T method is usually unknown. To approximate the \"best-fit\" PRS, we can perform a regression between PRS calculated at a range of P-value thresholds and then select the PRS that explains the highest phenotypic variance (please see Section 4.6 of our paper on overfitting issues). This can be achieved using R as follows: detail p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5) # Read in the phenotype file phenotype <- read.table(\"EUR.height\", header=T) # Read in the PCs pcs <- read.table(\"EUR.eigenvec\", header=F) # The default output from plink does not include a header # To make things simple, we will add the appropriate headers # (1:6 because there are 6 PCs) colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) # Read in the covariates (here, it is sex) covariate <- read.table(\"EUR.cov\", header=T) # Now merge the files pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\")) # We can then calculate the null model (model with PRS) using a linear regression # (as height is quantitative) null.model <- lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")]) # And the R2 of the null model is null.r2 <- summary(null.model)$r.squared prs.result <- NULL for(i in p.threshold){ # Go through each p-value threshold prs <- read.table(paste0(\"EUR.\",i,\".profile\"), header=T) # Merge the prs with the phenotype matrix # We only want the FID, IID and PRS from the PRS file, therefore we only select the # relevant columns pheno.prs <- merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\")) # Now perform a linear regression on Height with PRS and the covariates # ignoring the FID and IID from our model model <- lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")]) # model R2 is obtained as model.r2 <- summary(model)$r.squared # R2 of PRS is simply calculated as the model R2 minus the null R2 prs.r2 <- model.r2-null.r2 # We can also obtain the coeffcient and p-value of association of PRS as follow prs.coef <- summary(model)$coeff[\"SCORE\",] prs.beta <- as.numeric(prs.coef[1]) prs.se <- as.numeric(prs.coef[2]) prs.p <- as.numeric(prs.coef[4]) # We can then store the results prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se)) } # Best result is: prs.result[which.max(prs.result$R2),] q() # exit R quick p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5) phenotype <- read.table(\"EUR.height\", header=T) pcs <- read.table(\"EUR.eigenvec\", header=F) colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) covariate <- read.table(\"EUR.cov\", header=T) pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\")) null.r2 <- summary(lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")]))$r.squared prs.result <- NULL for(i in p.threshold){ pheno.prs <- merge(pheno, read.table(paste0(\"EUR.\",i,\".profile\"), header=T)[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\")) model <- summary(lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])) model.r2 <- model$r.squared prs.r2 <- model.r2-null.r2 prs.coef <- model$coeff[\"SCORE\",] prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=as.numeric(prs.coef[4]), BETA=as.numeric(prs.coef[1]), SE=as.numeric(prs.coef[2]))) } print(prs.result[which.max(prs.result$R2),]) q() # exit R with data.table and magrittr library(data.table) library(magrittr) p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5) phenotype <- fread(\"EUR.height\") pcs <- fread(\"EUR.eigenvec\", header=F) %>% setnames(., colnames(.), c(\"FID\", \"IID\", paste0(\"PC\",1:6)) ) covariate <- fread(\"EUR.cov\") pheno <- merge(phenotype, covariate) %>% merge(., pcs) null.r2 <- summary(lm(Height~., data=pheno[,-c(\"FID\", \"IID\")]))$r.squared prs.result <- NULL for(i in p.threshold){ pheno.prs <- paste0(\"EUR.\", i, \".profile\") %>% fread(.) %>% .[,c(\"FID\", \"IID\", \"SCORE\")] %>% merge(., pheno, by=c(\"FID\", \"IID\")) model <- lm(Height~., data=pheno.prs[,-c(\"FID\",\"IID\")]) %>% summary model.r2 <- model$r.squared prs.r2 <- model.r2-null.r2 prs.coef <- model$coeff[\"SCORE\",] prs.result %<>% rbind(., data.frame(Threshold=i, R2=prs.r2, P=as.numeric(prs.coef[4]), BETA=as.numeric(prs.coef[1]), SE=as.numeric(prs.coef[2]))) } print(prs.result[which.max(prs.result$R2),]) q() # exit R Which P-value threshold generates the \"best-fit\" PRS? 0.3 How much phenotypic variation does the \"best-fit\" PRS explain? 0.1638468","title":"PLINK"},{"location":"plink/#background","text":"On this page, you will compute PRS using the popular genetic analyses tool plink - while plink is not a dedicated PRS software, you can perform every required steps of the C+T approach with plink . This multi-step process is a good way to learn the processes involved in computing PRS, which are typically performed automatically by PRS software.","title":"Background"},{"location":"plink/#required-data","text":"In the previous sections, we have generated the following files: File Name Description Height.QC.gz The post-QCed summary statistic EUR.QC.bed The genotype file after performing some basic filtering EUR.QC.bim This file contains the SNPs that passed the basic filtering EUR.QC.fam This file contains the samples that passed the basic filtering EUR.height This file contains the phenotype of the samples EUR.cov This file contains the covariates of the samples","title":"Required Data"},{"location":"plink/#update-effect-size","text":"When the effect size relates to disease risk and is thus given as an odds ratio (OR), rather than BETA (for continuous traits), then the PRS is computed as a product of ORs. To simplify this calculation, we take the natural logarithm of the OR so that the PRS can be computed using summation instead (which can be back-transformed afterwards). We can obtain the transformed summary statistics with R : Without data.table dat <- read.table(gzfile(\"Height.QC.gz\"), header=T) dat$BETA <- log(dat$OR) write.table(dat, \"Height.QC.Transformed\", quote=F, row.names=F) q() # exit R With data.table library(data.table) dat <- fread(\"Height.QC.gz\") fwrite(dat[,BETA:=log(OR)], \"Height.QC.Transformed\", sep=\"\\t\") q() # exit R Warning Due to rounding of values, using awk to log transform OR can lead to less accurate results. Therefore, we recommend performing the transformation in R or allow the PRS software to perform the transformation directly.","title":"Update Effect Size"},{"location":"plink/#clumping","text":"Linkage disequilibrium, which corresponds to the correlation between the genotypes of genetic variants across the genome, makes identifying the contribution from causal independent genetic variants extremely challenging. One way of approximately capturing the right level of causal signal is to perform clumping, which removes SNPs in ways that only weakly correlated SNPs are retained but preferentially retaining the SNPs most associated with the phenotype under study. Clumping can be performed using the following command in plink : plink \\ --bfile EUR.QC \\ --clump-p1 1 \\ --clump-r2 0.1 \\ --clump-kb 250 \\ --clump Height.QC.Transformed \\ --clump-snp-field SNP \\ --clump-field P \\ --out EUR Each of the new parameters corresponds to the following Parameter Value Description clump-p1 1 P-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping clump-r2 0.1 SNPs having \\(r^2\\) higher than 0.1 with the index SNPs will be removed clump-kb 250 SNPs within 250k of the index SNP are considered for clumping clump Height.QC.Transformed Base data (summary statistic) file containing the P-value information clump-snp-field SNP Specifies that the column SNP contains the SNP IDs clump-field P Specifies that the column P contains the P-value information A more detailed description of the clumping process can be found here Note The \\(r^2\\) values computed by --clump are based on maximum likelihood haplotype frequency estimates This will generate EUR.clumped , containing the index SNPs after clumping is performed. We can extract the index SNP ID by performing the following command: awk 'NR!=1{print $3}' EUR.clumped > EUR.valid.snp $3 because the third column contains the SNP ID Note If your target data are small (e.g. N < 500) then you can use the 1000 Genomes Project samples for the LD calculation. Make sure to use the population that most closely reflects represents the base sample.","title":"Clumping"},{"location":"plink/#generate-prs","text":"plink provides a convenient function --score and --q-score-range for calculating polygenic scores. We will need three files: The base data file: Height.QC.Transformed A file containing SNP IDs and their corresponding P-values ( $3 because SNP ID is located in the third column; $8 because the P-value is located in the eighth column) awk '{print $3,$8}' Height.QC.Transformed > SNP.pvalue A file containing the different P-value thresholds for inclusion of SNPs in the PRS. Here calculate PRS corresponding to a few thresholds for illustration purposes: echo \"0.001 0 0.001\" > range_list echo \"0.05 0 0.05\" >> range_list echo \"0.1 0 0.1\" >> range_list echo \"0.2 0 0.2\" >> range_list echo \"0.3 0 0.3\" >> range_list echo \"0.4 0 0.4\" >> range_list echo \"0.5 0 0.5\" >> range_list The format of the range_list file should be as follows: Name of Threshold Lower bound Upper Bound Note The threshold boundaries are inclusive. For example, for the 0.05 threshold, we include all SNPs with P-value from 0 to 0.05 , including any SNPs with P-value equal to 0.05 . We can then calculate the PRS with the following plink command: plink \\ --bfile EUR.QC \\ --score Height.QC.Transformed 3 4 12 header \\ --q-score-range range_list SNP.pvalue \\ --extract EUR.valid.snp \\ --out EUR The meaning of the new parameters are as follows: Paramter Value Description score Height.QC.Transformed 3 4 12 header We read from the Height.QC.Transformed file, assuming that the 3 st column is the SNP ID; 4 th column is the effective allele information; the 12 th column is the effect size estimate; and that the file contains a header q-score-range range_list SNP.pvalue We want to calculate PRS based on the thresholds defined in range_list , where the threshold values (P-values) were stored in SNP.pvalue The above command and range_list will generate 7 files: EUR.0.5.profile EUR.0.4.profile EUR.0.3.profile EUR.0.2.profile EUR.0.1.profile EUR.0.05.profile EUR.0.001.profile Note The default formula for PRS calculation in PLINK is: \\[ PRS_j =\\frac{ \\sum_i^NS_i*G_{ij}}{P*M_j} \\] where the effect size of SNP \\(i\\) is \\(S_i\\) ; the number of effect alleles observed in sample \\(j\\) is \\(G_{ij}\\) ; the ploidy of the sample is \\(P\\) (is generally 2 for humans); the total number of SNPs included in the PRS is \\(N\\) ; and the number of non-missing SNPs observed in sample \\(j\\) is \\(M_j\\) . If the sample has a missing genotype for SNP \\(i\\) , then the population minor allele frequency multiplied by the ploidy ( \\(MAF_i*P\\) ) is used instead of \\(G_{ij}\\) .","title":"Generate PRS"},{"location":"plink/#accounting-for-population-stratification","text":"Population structure is the principal source of confounding in GWAS and is usually accounted for by incorporating principal components (PCs) as covariates. We can incorporate PCs into our PRS analysis to account for population stratification. Again, we can calculate the PCs using plink : # First, we need to perform prunning plink \\ --bfile EUR.QC \\ --indep-pairwise 200 50 0.25 \\ --out EUR # Then we calculate the first 6 PCs plink \\ --bfile EUR.QC \\ --extract EUR.prune.in \\ --pca 6 \\ --out EUR Note One way to select the appropriate number of PCs is to perform GWAS on the phenotype under study with different numbers of PCs. LDSC analysis can then be performed on the set of GWAS summary statistics and the GWAS that used the number of PCs that gave an LDSC intercept closest to 1 should correspond to that for which population structure was most accurately controlled for. Here the PCs have been stored in the EUR.eigenvec file and can be used as covariates in the regression model to account for population stratification. Important If the base and target samples are collected from different worldwide populations then the results from the PRS analysis may be biased (see Section 3.4 of our papper).","title":"Accounting for Population Stratification"},{"location":"plink/#finding-the-best-fit-prs","text":"The P-value threshold that provides the \"best-fit\" PRS under the C+T method is usually unknown. To approximate the \"best-fit\" PRS, we can perform a regression between PRS calculated at a range of P-value thresholds and then select the PRS that explains the highest phenotypic variance (please see Section 4.6 of our paper on overfitting issues). This can be achieved using R as follows: detail p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5) # Read in the phenotype file phenotype <- read.table(\"EUR.height\", header=T) # Read in the PCs pcs <- read.table(\"EUR.eigenvec\", header=F) # The default output from plink does not include a header # To make things simple, we will add the appropriate headers # (1:6 because there are 6 PCs) colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) # Read in the covariates (here, it is sex) covariate <- read.table(\"EUR.cov\", header=T) # Now merge the files pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\")) # We can then calculate the null model (model with PRS) using a linear regression # (as height is quantitative) null.model <- lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")]) # And the R2 of the null model is null.r2 <- summary(null.model)$r.squared prs.result <- NULL for(i in p.threshold){ # Go through each p-value threshold prs <- read.table(paste0(\"EUR.\",i,\".profile\"), header=T) # Merge the prs with the phenotype matrix # We only want the FID, IID and PRS from the PRS file, therefore we only select the # relevant columns pheno.prs <- merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\")) # Now perform a linear regression on Height with PRS and the covariates # ignoring the FID and IID from our model model <- lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")]) # model R2 is obtained as model.r2 <- summary(model)$r.squared # R2 of PRS is simply calculated as the model R2 minus the null R2 prs.r2 <- model.r2-null.r2 # We can also obtain the coeffcient and p-value of association of PRS as follow prs.coef <- summary(model)$coeff[\"SCORE\",] prs.beta <- as.numeric(prs.coef[1]) prs.se <- as.numeric(prs.coef[2]) prs.p <- as.numeric(prs.coef[4]) # We can then store the results prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se)) } # Best result is: prs.result[which.max(prs.result$R2),] q() # exit R quick p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5) phenotype <- read.table(\"EUR.height\", header=T) pcs <- read.table(\"EUR.eigenvec\", header=F) colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) covariate <- read.table(\"EUR.cov\", header=T) pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\")) null.r2 <- summary(lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")]))$r.squared prs.result <- NULL for(i in p.threshold){ pheno.prs <- merge(pheno, read.table(paste0(\"EUR.\",i,\".profile\"), header=T)[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\")) model <- summary(lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])) model.r2 <- model$r.squared prs.r2 <- model.r2-null.r2 prs.coef <- model$coeff[\"SCORE\",] prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=as.numeric(prs.coef[4]), BETA=as.numeric(prs.coef[1]), SE=as.numeric(prs.coef[2]))) } print(prs.result[which.max(prs.result$R2),]) q() # exit R with data.table and magrittr library(data.table) library(magrittr) p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5) phenotype <- fread(\"EUR.height\") pcs <- fread(\"EUR.eigenvec\", header=F) %>% setnames(., colnames(.), c(\"FID\", \"IID\", paste0(\"PC\",1:6)) ) covariate <- fread(\"EUR.cov\") pheno <- merge(phenotype, covariate) %>% merge(., pcs) null.r2 <- summary(lm(Height~., data=pheno[,-c(\"FID\", \"IID\")]))$r.squared prs.result <- NULL for(i in p.threshold){ pheno.prs <- paste0(\"EUR.\", i, \".profile\") %>% fread(.) %>% .[,c(\"FID\", \"IID\", \"SCORE\")] %>% merge(., pheno, by=c(\"FID\", \"IID\")) model <- lm(Height~., data=pheno.prs[,-c(\"FID\",\"IID\")]) %>% summary model.r2 <- model$r.squared prs.r2 <- model.r2-null.r2 prs.coef <- model$coeff[\"SCORE\",] prs.result %<>% rbind(., data.frame(Threshold=i, R2=prs.r2, P=as.numeric(prs.coef[4]), BETA=as.numeric(prs.coef[1]), SE=as.numeric(prs.coef[2]))) } print(prs.result[which.max(prs.result$R2),]) q() # exit R Which P-value threshold generates the \"best-fit\" PRS? 0.3 How much phenotypic variation does the \"best-fit\" PRS explain? 0.1638468","title":"Finding the \"best-fit\" PRS"},{"location":"plink_visual/","text":"Plotting the Results \u00b6 The PRS results corresponding to a range of P-value thresholds obtained by application of the C+T PRS method (eg. using PLINK or PRSice-2) can be visualised using R as follows: Note We will be using prs.result variable, which was generated in the previous section Without ggplot2 # We strongly recommend the use of ggplot2. Only follow this code if you # are desperate. # Specify that we want to generate plot in EUR.height.bar.png png(\"EUR.height.bar.png\", height=10, width=10, res=300, unit=\"in\") # First, obtain the colorings based on the p-value col <- suppressWarnings(colorRampPalette(c(\"dodgerblue\", \"firebrick\"))) # We want the color gradient to match the ranking of p-values prs.result <- prs.result[order(-log10(prs.result$P)),] prs.result$color <- col(nrow(prs.result)) prs.result <- prs.result[order(prs.result$Threshold),] # generate a pretty format for p-value output prs.result$print.p <- round(prs.result$P, digits = 3) prs.result$print.p[!is.na(prs.result$print.p) & prs.result$print.p == 0 ] <- format(prs.result$P[!is.na(prs.result$print.p) & prs.result$print.p == 0 ], digits = 2) prs.result$print.p <- sub(\"e\", \"*x*10^\", prs.result$print.p) # Generate the axis labels xlab <- expression(italic(P) - value ~ threshold ~ (italic(P)[T])) ylab <- expression(paste(\"PRS model fit: \", R ^ 2)) # Setup the drawing area layout(t(1:2), widths=c(8.8,1.2)) par( cex.lab=1.5, cex.axis=1.25, font.lab=2, oma=c(0,0.5,0,0), mar=c(4,6,0.5,0.5)) # Plotting the bars b<- barplot(height=prs.result$R2, col=prs.result$color, border=NA, ylim=c(0, max(prs.result$R2)*1.25), axes = F, ann=F) # Plot the axis labels and axis ticks odd <- seq(0,nrow(prs.result)+1,2) even <- seq(1,nrow(prs.result),2) axis(side=1, at=b[odd], labels=prs.result$Threshold[odd], lwd=2) axis(side=1, at=b[even], labels=prs.result$Threshold[even],lwd=2) axis(side=1, at=c(0,b[1],2*b[length(b)]-b[length(b)-1]), labels=c(\"\",\"\",\"\"), lwd=2, lwd.tick=0) # Write the p-value on top of each bar text( parse(text=paste( prs.result$print.p)), x = b+0.1, y = prs.result$R2+ (max(prs.result$R2)*1.05-max(prs.result$R2)), srt = 45) # Now plot the axis lines box(bty='L', lwd=2) axis(2,las=2, lwd=2) # Plot the axis titles title(ylab=ylab, line=4, cex.lab=1.5, font=2 ) title(xlab=xlab, line=2.5, cex.lab=1.5, font=2 ) # Generate plot area for the legend par(cex.lab=1.5, cex.axis=1.25, font.lab=2, mar=c(20,0,20,4)) prs.result <- prs.result[order(-log10(prs.result$P)),] image(1, -log10(prs.result$P), t(seq_along(-log10(prs.result$P))), col=prs.result$color, axes=F,ann=F) axis(4,las=2,xaxs='r',yaxs='r', tck=0.2, col=\"white\") # plot legend title title(bquote(atop(-log[10] ~ model, italic(P) - value), ), line=2, cex=1.5, font=2, adj=0) # write the plot to file dev.off() q() # exit R ggplot2 # ggplot2 is a handy package for plotting library(ggplot2) # generate a pretty format for p-value output prs.result$print.p <- round(prs.result$P, digits = 3) prs.result$print.p[!is.na(prs.result$print.p) & prs.result$print.p == 0] <- format(prs.result$P[!is.na(prs.result$print.p) & prs.result$print.p == 0], digits = 2) prs.result$print.p <- sub(\"e\", \"*x*10^\", prs.result$print.p) # Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed) ggplot(data = prs.result, aes(x = factor(Threshold), y = R2)) + # Specify that we want to print p-value on top of the bars geom_text( aes(label = paste(print.p)), vjust = -1.5, hjust = 0, angle = 45, cex = 4, parse = T ) + # Specify the range of the plot, *1.25 to provide enough space for the p-values scale_y_continuous(limits = c(0, max(prs.result$R2) * 1.25)) + # Specify the axis labels xlab(expression(italic(P) - value ~ threshold ~ (italic(P)[T]))) + ylab(expression(paste(\"PRS model fit: \", R ^ 2))) + # Draw a bar plot geom_bar(aes(fill = -log10(P)), stat = \"identity\") + # Specify the colors scale_fill_gradient2( low = \"dodgerblue\", high = \"firebrick\", mid = \"dodgerblue\", midpoint = 1e-4, name = bquote(atop(-log[10] ~ model, italic(P) - value),) ) + # Some beautification of the plot theme_classic() + theme( axis.title = element_text(face = \"bold\", size = 18), axis.text = element_text(size = 14), legend.title = element_text(face = \"bold\", size = 18), legend.text = element_text(size = 14), axis.text.x = element_text(angle = 45, hjust = 1) ) # save the plot ggsave(\"EUR.height.bar.png\", height = 7, width = 7) q() # exit R An example bar plot generated using ggplot2 In addition, we can visualise the relationship between the \"best-fit\" PRS (which may have been obtained from any of the PRS programs) and the phenotype of interest, coloured according to sex: Without ggplot2 # Read in the files prs <- read.table(\"EUR.0.3.profile\", header=T) height <- read.table(\"EUR.height\", header=T) sex <- read.table(\"EUR.cov\", header=T) # Rename the sex sex$Sex <- as.factor(sex$Sex) levels(sex$Sex) <- c(\"Male\", \"Female\") # Merge the files dat <- merge(merge(prs, height), sex) # Start plotting plot(x=dat$SCORE, y=dat$Height, col=\"white\", xlab=\"Polygenic Score\", ylab=\"Height\") with(subset(dat, Sex==\"Male\"), points(x=SCORE, y=Height, col=\"red\")) with(subset(dat, Sex==\"Female\"), points(x=SCORE, y=Height, col=\"blue\")) q() # exit R ggplot2 library(ggplot2) # Read in the files prs <- read.table(\"EUR.0.3.profile\", header=T) height <- read.table(\"EUR.height\", header=T) sex <- read.table(\"EUR.cov\", header=T) # Rename the sex sex$Sex <- as.factor(sex$Sex) levels(sex$Sex) <- c(\"Male\", \"Female\") # Merge the files dat <- merge(merge(prs, height), sex) # Start plotting ggplot(dat, aes(x=SCORE, y=Height, color=Sex))+ geom_point()+ theme_classic()+ labs(x=\"Polygenic Score\", y=\"Height\") q() # exit R An example scatter plot generated using ggplot2 Programs such as PRSice-2 and bigsnpr include numerous options for plotting PRS results.","title":"4. Visualizing association results"},{"location":"plink_visual/#plotting-the-results","text":"The PRS results corresponding to a range of P-value thresholds obtained by application of the C+T PRS method (eg. using PLINK or PRSice-2) can be visualised using R as follows: Note We will be using prs.result variable, which was generated in the previous section Without ggplot2 # We strongly recommend the use of ggplot2. Only follow this code if you # are desperate. # Specify that we want to generate plot in EUR.height.bar.png png(\"EUR.height.bar.png\", height=10, width=10, res=300, unit=\"in\") # First, obtain the colorings based on the p-value col <- suppressWarnings(colorRampPalette(c(\"dodgerblue\", \"firebrick\"))) # We want the color gradient to match the ranking of p-values prs.result <- prs.result[order(-log10(prs.result$P)),] prs.result$color <- col(nrow(prs.result)) prs.result <- prs.result[order(prs.result$Threshold),] # generate a pretty format for p-value output prs.result$print.p <- round(prs.result$P, digits = 3) prs.result$print.p[!is.na(prs.result$print.p) & prs.result$print.p == 0 ] <- format(prs.result$P[!is.na(prs.result$print.p) & prs.result$print.p == 0 ], digits = 2) prs.result$print.p <- sub(\"e\", \"*x*10^\", prs.result$print.p) # Generate the axis labels xlab <- expression(italic(P) - value ~ threshold ~ (italic(P)[T])) ylab <- expression(paste(\"PRS model fit: \", R ^ 2)) # Setup the drawing area layout(t(1:2), widths=c(8.8,1.2)) par( cex.lab=1.5, cex.axis=1.25, font.lab=2, oma=c(0,0.5,0,0), mar=c(4,6,0.5,0.5)) # Plotting the bars b<- barplot(height=prs.result$R2, col=prs.result$color, border=NA, ylim=c(0, max(prs.result$R2)*1.25), axes = F, ann=F) # Plot the axis labels and axis ticks odd <- seq(0,nrow(prs.result)+1,2) even <- seq(1,nrow(prs.result),2) axis(side=1, at=b[odd], labels=prs.result$Threshold[odd], lwd=2) axis(side=1, at=b[even], labels=prs.result$Threshold[even],lwd=2) axis(side=1, at=c(0,b[1],2*b[length(b)]-b[length(b)-1]), labels=c(\"\",\"\",\"\"), lwd=2, lwd.tick=0) # Write the p-value on top of each bar text( parse(text=paste( prs.result$print.p)), x = b+0.1, y = prs.result$R2+ (max(prs.result$R2)*1.05-max(prs.result$R2)), srt = 45) # Now plot the axis lines box(bty='L', lwd=2) axis(2,las=2, lwd=2) # Plot the axis titles title(ylab=ylab, line=4, cex.lab=1.5, font=2 ) title(xlab=xlab, line=2.5, cex.lab=1.5, font=2 ) # Generate plot area for the legend par(cex.lab=1.5, cex.axis=1.25, font.lab=2, mar=c(20,0,20,4)) prs.result <- prs.result[order(-log10(prs.result$P)),] image(1, -log10(prs.result$P), t(seq_along(-log10(prs.result$P))), col=prs.result$color, axes=F,ann=F) axis(4,las=2,xaxs='r',yaxs='r', tck=0.2, col=\"white\") # plot legend title title(bquote(atop(-log[10] ~ model, italic(P) - value), ), line=2, cex=1.5, font=2, adj=0) # write the plot to file dev.off() q() # exit R ggplot2 # ggplot2 is a handy package for plotting library(ggplot2) # generate a pretty format for p-value output prs.result$print.p <- round(prs.result$P, digits = 3) prs.result$print.p[!is.na(prs.result$print.p) & prs.result$print.p == 0] <- format(prs.result$P[!is.na(prs.result$print.p) & prs.result$print.p == 0], digits = 2) prs.result$print.p <- sub(\"e\", \"*x*10^\", prs.result$print.p) # Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed) ggplot(data = prs.result, aes(x = factor(Threshold), y = R2)) + # Specify that we want to print p-value on top of the bars geom_text( aes(label = paste(print.p)), vjust = -1.5, hjust = 0, angle = 45, cex = 4, parse = T ) + # Specify the range of the plot, *1.25 to provide enough space for the p-values scale_y_continuous(limits = c(0, max(prs.result$R2) * 1.25)) + # Specify the axis labels xlab(expression(italic(P) - value ~ threshold ~ (italic(P)[T]))) + ylab(expression(paste(\"PRS model fit: \", R ^ 2))) + # Draw a bar plot geom_bar(aes(fill = -log10(P)), stat = \"identity\") + # Specify the colors scale_fill_gradient2( low = \"dodgerblue\", high = \"firebrick\", mid = \"dodgerblue\", midpoint = 1e-4, name = bquote(atop(-log[10] ~ model, italic(P) - value),) ) + # Some beautification of the plot theme_classic() + theme( axis.title = element_text(face = \"bold\", size = 18), axis.text = element_text(size = 14), legend.title = element_text(face = \"bold\", size = 18), legend.text = element_text(size = 14), axis.text.x = element_text(angle = 45, hjust = 1) ) # save the plot ggsave(\"EUR.height.bar.png\", height = 7, width = 7) q() # exit R An example bar plot generated using ggplot2 In addition, we can visualise the relationship between the \"best-fit\" PRS (which may have been obtained from any of the PRS programs) and the phenotype of interest, coloured according to sex: Without ggplot2 # Read in the files prs <- read.table(\"EUR.0.3.profile\", header=T) height <- read.table(\"EUR.height\", header=T) sex <- read.table(\"EUR.cov\", header=T) # Rename the sex sex$Sex <- as.factor(sex$Sex) levels(sex$Sex) <- c(\"Male\", \"Female\") # Merge the files dat <- merge(merge(prs, height), sex) # Start plotting plot(x=dat$SCORE, y=dat$Height, col=\"white\", xlab=\"Polygenic Score\", ylab=\"Height\") with(subset(dat, Sex==\"Male\"), points(x=SCORE, y=Height, col=\"red\")) with(subset(dat, Sex==\"Female\"), points(x=SCORE, y=Height, col=\"blue\")) q() # exit R ggplot2 library(ggplot2) # Read in the files prs <- read.table(\"EUR.0.3.profile\", header=T) height <- read.table(\"EUR.height\", header=T) sex <- read.table(\"EUR.cov\", header=T) # Rename the sex sex$Sex <- as.factor(sex$Sex) levels(sex$Sex) <- c(\"Male\", \"Female\") # Merge the files dat <- merge(merge(prs, height), sex) # Start plotting ggplot(dat, aes(x=SCORE, y=Height, color=Sex))+ geom_point()+ theme_classic()+ labs(x=\"Polygenic Score\", y=\"Height\") q() # exit R An example scatter plot generated using ggplot2 Programs such as PRSice-2 and bigsnpr include numerous options for plotting PRS results.","title":"Plotting the Results"},{"location":"popstrat/","text":"Population Stratifacation \u00b6 Obtaining the 1000 genome reference data set \u00b6 We will be using data from the 1000 Genomes Project for the population stratification step. You can download using the following command wget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz The data will need to be converted into plink format with unique indentifiers created for each the SNPs with a missing rs-identifier: Note You will need plink in this section, which can be download from here . Install the program plink and include its location in your PATH directory, which allows us to use plink instead of ./plink in the commands below. If PLINK is not in your PATH directory and is instead in your working directory, replace all instances of plink in the tutorial with ./plink . plink --vcf ALL.2of4intersection.20100804.genotypes.vcf.gz --make-bed --out 1000genomes.genotypes plink --bfile 1000genomes.genotypes --set-missing-var-ids @:#[b37]\\$1,\\$2 --make-bed --out 1000genomes_nomissing.genotypes Define Variables to be used in this section \u00b6 input files and variables FILE_1K=1000genomes_nomissing.genotypes #1000 genomes file FILE_QC=qcout #file from qc tab FILE_PRUNEIN=plink.prune.in #snps in approximate linkage equilibrium GENO=0.02 #snp missingness filter INDV=0.02 #individual missingness filter MAF=0.05 #minor allele frequency filter HWE_CONTROL=1e-6 #hardy weinburg equilibrium filter define general file tags sep=\"_\" tagbed=\".bed\" tagbim=\".bim\" tagfam=\".fam\" tagmap=\".map\" tags for filtering 1000genome data TAG_1kG=\"1KG\" TAG_GENO=\"geno\" OUT1=\"$TAG_1kG$sep$TAG_GENO$sep$GENO\" TAG_MIND=\"mind\" OUT2=\"$OUT1$sep$TAG_MIND$sep$INDV\" TAG_MAF=\"maf\" OUT3=$OUT2$sep$TAG_MAF$sep$MAF TAG_extract=\"extract\" OUT4=$OUT3$sep$TAG_extract TAG_BUILD=\"samebuild\" OUT5=$OUT4$sep$TAG_BUILD TAG_REM=\"removeproblem\" OUT6=$OUT5$sep$TAG_REM tags for filtering QCed data TAG_QC=\"QCin\" OUT1_QC=$TAG_QC$sep$TAG_extract OUT2_QC=$OUT1_QC$sep$TAG_REM tag_euro=\"euro\" FILEQCEURO=$FILE_QC$sep$tag_euro QC on 1000 Genomes data. \u00b6 Remove variants based on missing genotype data. plink --bfile $FILE_1K --geno $GENO --make-bed --out $OUT1 Remove individuals based on missing genotype data plink --bfile $OUT1 --mind $INDV --allow-no-sex --make-bed --out $OUT2 Remove variants based on MAF plink --bfile $OUT2 --maf $MAF --make-bed --out $OUT3 Extract the variants present in our dataset from the 1000 genomes dataset awk '{print$2}' \"$FILE_QC$tagbim\"> QCFILE_SNPs.txt awk '{print$2}' \"$OUT3$tagbim\"> 1kG_temp.bim plink --bfile $OUT3 --extract QCFILE_SNPs.txt --make-bed --recode --out $OUT4 Extract the variants present in 1000 Genomes dataset from your dataset. \u00b6 awk '{print$2}' $OUT4$tagbim > 1kG_SNPs.txt plink --bfile $FILE_QC --extract 1kG_SNPs.txt --recode --make-bed --out $OUT1_QC The datasets now contain the exact same variants. Change build on 1000 Genomes data build to match build of HapMap data \u00b6 Note Look at Liftover tutorial to see how to move data set to another build. awk '{print$2,$4}' $OUT1_QC$tagmap > buildmap.txt # buildmap.txt contains one SNP-id and physical position per line. plink --bfile $OUT4 --update-map buildmap.txt --make-bed --out $OUT5 Merge the Map and 1000 Genomes data sets \u00b6 Prior to merging 1000 Genomes data with the data we want to make sure that the files are mergeable, for this we conduct 3 steps: 1) Make sure the reference genome is similar in your data and the 1000 Genomes Project datasets 2) Resolve strand issues. 3) Remove the SNPs which after the previous two steps still differ between datasets 1) set reference genome awk '{print$2,$5}' $OUT5$tagbim > 1kg_ref-list.txt plink --bfile $OUT1_QC --reference-allele 1kg_ref-list.txt --make-bed --out Map-adj # The 1kG_MDS6 and the HapMap-adj have the same reference genome for all SNPs. 2) Resolve strand issues awk '{print$2,$5,$6}' $OUT5$tagbim > 1kGMDS_strand_tmp awk '{print$2,$5,$6}' Map-adj.bim > Map-adj_tmp sort 1kGMDS_strand_tmp Map-adj_tmp |uniq -u > all_differences.txt Flip SNPs for resolving strand issues awk '{print$1}' all_differences.txt | sort -u > flip_list.txt plink --bfile Map-adj --flip flip_list.txt --reference-allele 1kg_ref-list.txt --make-bed --out corrected_map Check for SNPs which are still problematic after they have been flipped. awk '{print$2,$5,$6}' corrected_map.bim > corrected_map_tmp sort 1kGMDS_strand_tmp corrected_map_tmp |uniq -u > uncorresponding_SNPs.txt 3) Remove problematic SNPs from your data and from the 1000 Genomes. awk '{print$1}' uncorresponding_SNPs.txt | sort -u > SNPs_for_exclusion.txt plink --bfile corrected_map --exclude SNPs_for_exclusion.txt --make-bed --out $OUT2_QC plink --bfile $OUT5 --exclude SNPs_for_exclusion.txt --make-bed --out $OUT6 Merge outdata with 1000 Genomes Data \u00b6 plink --bfile $OUT2_QC --bmerge $OUT6$tagbed $OUT6$tagbim $OUT6$tagfam --allow-no-sex --make-bed --out MDS_merge2 Perform MDS on Map-CEU data anchored by 1000 Genomes data. \u00b6 Using a set of pruned SNPs \u00b6 plink --bfile MDS_merge2 --extract $FILE_PRUNEIN --genome --out MDS_merge2 plink --bfile MDS_merge2 --read-genome MDS_merge2.genome --cluster --mds-plot 10 --out MDS_merge2 MDS-plot \u00b6 Download the file with population information of the 1000 genomes dataset. \u00b6 wget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/20100804.ALL.panel The file 20130502.ALL.panel contains population codes of the individuals of 1000 genomes. \u00b6 Convert population codes into superpopulation codes (i.e., AFR,AMR,ASN, and EUR). \u00b6 awk '{print \\(1,\\) 1,$2}' 20100804.ALL.panel > race_1kG.txt Create a racefile of your own data. \u00b6 awk '{print \\(1,\\) 2,\"-\"}' \\(OUT2_QC\\) tagfam > racefile_own.txt Concatenate racefiles. \u00b6 cat racefile_own.txt race_1kG.txt| sed -e '1i\\FID IID race' > MDS_merge2.pop sed -i -e \"1d\" MDS_merge2.pop cut -d \" \" -f 3- MDS_merge2.pop >temp.txt make popfile for admixture script \u00b6 mv temp.txt MDS_merge2.pop conda install -c bioconda admixture \u00b6 #####run admixture script \u00b6 qsub -cwd -pe smp 8 -l mem_free=32G -l scratch=100G -l h_rt=40:20:00 ad.sh admixture --supervised ./MDS_merge2.bed 12 > log_merge_admixture.out Rscript --no-save ../R/admixtureplot.R european.txt file comes from admixture script \u00b6 sed 's/JPT/ASN/g' race_1kG.txt>race_1kG2.txt sed 's/ASW/AFR/g' race_1kG2.txt>race_1kG3.txt sed 's/CEU/EUR/g' race_1kG3.txt>race_1kG4.txt sed 's/CHB/ASN/g' race_1kG4.txt>race_1kG5.txt sed 's/CHD/ASN/g' race_1kG5.txt>race_1kG6.txt sed 's/YRI/AFR/g' race_1kG6.txt>race_1kG7.txt sed 's/LWK/AFR/g' race_1kG7.txt>race_1kG8.txt sed 's/TSI/EUR/g' race_1kG8.txt>race_1kG9.txt sed 's/MXL/AMR/g' race_1kG9.txt>race_1kG10.txt sed 's/GBR/EUR/g' race_1kG10.txt>race_1kG11.txt sed 's/FIN/EUR/g' race_1kG11.txt>race_1kG12.txt sed 's/CHS/ASN/g' race_1kG12.txt>race_1kG13.txt sed 's/PUR/AMR/g' race_1kG13.txt>race_1kG14.txt Create a racefile of your own data. \u00b6 awk '{print \\(1,\\) 2,\"OWN\"}' \\(OUT2_QC\\) tagfam > racefile_own.txt Concatenate racefiles. \u00b6 cat race_1kG14.txt racefile_own.txt | sed -e '1i\\FID IID race' > racefile.txt Generate population stratification plot. \u00b6 Rscript ../R/MDS_merged.R Exclude ethnic outliers. \u00b6 Select individuals in your own data below cut-off thresholds. The cut-off levels are not fixed ithresholds but have to be determined based on the visualization of the first two dimensions. To exclude ethnic outliers, the thresholds need to be set around the cluster of population of interest. \u00b6 awk '{ if ($4 <-0.04 && $5 >0.03) print \\(1,\\) 2 }' MDS_merge2.mds > EUR_MDS_merge2 \u00b6 below are the filters used for my own HA data \u00b6 awk '{ if ($4 < 0.1 && $4 > -0.05 && $5 > -0.1 && $5 < 0.03) print \\(1,\\) 2 }' MDS_merge2.mds > EUR_MDS_merge2 \u00b6 tag_euro=\"euro\" \u00b6 FILEQCEURO= \\(FILE_QC\\) sep$tag_euro \u00b6 plink --bfile $FILE_QC --keep EUR_MDS_merge2 --make-bed --out $FILEQCEURO \u00b6 Exclude ethnic outliers. \u00b6 plink --bfile $FILE_QC --keep europeans.txt --make-bed --out $FILEQCEURO plink --bfile $FILE_QC --keep EUR_MDS_merge2 --make-bed --out $FILEQCEURO \u00b6 HWE Limitations \u00b6 TAG_HWE_CONTROL=\"hwe_control\" OUTQCEURO= \\(FILEQCEURO\\) sep \\(TAG_HWE_CONTROL\\) sep$HWE_CONTROL echo \"plink --bfile $FILEQCEURO --hwe $HWE_CONTROL --make-bed --out $OUTQCEURO\" plink --bfile $FILEQCEURO --hwe $HWE_CONTROL --make-bed --out $OUTQCEURO In this tutorial, we aim to remove all 'relatedness' from our dataset. \u00b6 To demonstrate that the majority of the relatedness was due to parent-offspring we only include founders (individuals without parents in the dataset). \u00b6 found=\"founder\" plink --bfile \\(OUTQCEURO --filter-founders --make-bed --out \\(OUTQCEURO\\) sep\\) found #Check for cryptic relatedness \u00b6 install king and run \u00b6 plink2 --bfile \\(OUTQCEURO\\) sep$found --make-king-table --king-table-filter 0.0884 sed 's/^#//' plink2.kin0 > kin.txt plink --bfile \\(OUTQCEURO\\) sep \\(found --missing Rscript ../R/Relatedness_cpw.R lowcover=\"unrelated\" OUTCOVER=\\) lowcover plink --bfile \\(OUTQCEURO\\) sep$found --remove 0.2_low_call_rate.txt --make-bed --out $OUTCOVER Create covariates based on MDS. \u00b6 Perform an MDS ONLY on qccase data without ethnic outliers. The values of the 10 MDS dimensions are subsequently used as covariates in the association analysis in the third tutorial. \u00b6 plink --bfile $OUTCOVER --extract plink.prune.in --genome --out $OUTCOVER tag_mds=\"MDS\" POPSTRATOUT= \\(OUTCOVER\\) sep$tag_mds taggenome=\".genome\" echo \"plink --bfile $OUTCOVER --read-genome \\(OUTCOVER\\) taggenome --cluster --mds-plot 10 --out $POPSTRATOUT\" plink --bfile $OUTCOVER --read-genome \\(OUTCOVER\\) taggenome --cluster --mds-plot 10 --out $POPSTRATOUT tag_dot_mds=\".mds\" Change the format of the .mds file into a plink covariate file. \u00b6 awk '{print \\(1, (2, (4, (5, (6, \\(7,\\) 8,\\) 9,\\) 10,\\) 11,\\) 12,\\) 13}' \\(POPSTRATOUT\\) tag_dot_mds > covar_mds.txt The values in covar_mds.txt will be used as covariates, to adjust for remaining population stratification, in the third tutorial where we will perform a genome-wide association analysis. \u00b6 mv \\(OUTCOVER\\) tagbed ./popstratout.bed mv \\(OUTCOVER\\) tagbim ./popstratout.bim mv \\(OUTCOVER\\) tagfam ./popstratout.fam cp popstratout* ../3_Association_GWAS cp covar_mds.txt ../3_Association_GWAS cd ../3_Association_GWAS # Sample size \u00b6 We recommend that users only perform PRS analyses on target data of at least 100 individuals. The sample size of our target data here is 503 individuals. # File transfer \u00b6 Usually we do not need to download and transfer the target data file because it is typically generated locally. However, the file should contain an md5sum code in case we send the data file to collaborators who may want to confirm that the file has not changed during the transfer. What is the md5sum code for each of the target files? File md5sum EUR.bed 98bcef133f683b1272d3ea5f97742e0e EUR.bim 6b286002904880055a9c94e01522f059 EUR.cov 85ed18288c708e095385418517e9c3bd EUR.fam e7b856f0c7bcaffc8405926d08386e97 EUR.height dd445ce969a81cded20da5c88b82d4df # Genome build \u00b6 As stated in the base data section, the genome build for our base and target data is the same, as it should be. # Standard GWAS QC \u00b6 The target data must be quality controlled to at least the standards implemented in GWAS studies, e.g. removing SNPs with low genotyping rate, low minor allele frequency, out of Hardy-Weinberg Equilibrium, removing individuals with low genotyping rate (see Marees et al ). The following plink command applies some of these QC metrics to the target data: plink \\ --bfile EUR \\ --maf 0.01 \\ --hwe 1e-6 \\ --geno 0.01 \\ --mind 0.01 \\ --write-snplist \\ --make-just-fam \\ --out EUR.QC Each of the parameters corresponds to the following Paramter Value Description bfile EUR Informs plink that the input genotype files should have a prefix of EUR maf 0.01 Removes all SNPs with minor allele frequency less than 0.05. Genotyping errors typically have a larger influence on SNPs with low MAF. Studies with large sample sizes could apply a lower MAF threshold hwe 1e-6 Removes SNPs with low P-value from the Hardy-Weinberg Equilibrium Fisher's exact or chi-squared test. SNPs with significant P-values from the HWE test are more likely affected by genotyping error or the effects of natural selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases). When phenotype information is included, plink will automatically perform the filtering in the controls. geno 0.01 Excludes SNPs that are missing in a high fraction of subjects. A two-stage filtering process is usually performed (see Marees et al ). mind 0.01 Excludes individuals who have a high rate of genotype missingness, since this may indicate problems in the DNA sample or processing. (see Marees et al for more details). make-just-fam - Informs plink to only generate the QC'ed sample name to avoid generating the .bed file. write-snplist - Informs plink to only generate the QC'ed SNP list to avoid generating the .bed file. out EUR.QC Informs plink that all output should have a prefix of EUR.QC How many SNPs and samples were filtered? 14 samples were removed due to a high rate of genotype missingness 5,353 SNP were removed due to missing genotype data 944 SNPs were removed due to being out of Hardy-Weinberg Equilibrium 5,061 SNPs were removed due to low minor allele frequency Note Normally, we can generate a new genotype file using the new sample list. However, this will use up a lot of storage space. Using plink 's --extract , --exclude , --keep , --remove , --make-just-fam and --write-snplist functions, we can work solely on the list of samples and SNPs without duplicating the genotype file, reducing the storage space usage. Very high or low heterozygosity rates in individuals could be due to DNA contamination or to high levels of inbreeding. Therefore, samples with extreme heterozygosity are typically removed prior to downstream analyses. First, we perform prunning to remove highly correlated SNPs: plink \\ --bfile EUR \\ --keep EUR.QC.fam \\ --extract EUR.QC.snplist \\ --indep-pairwise 200 50 0.25 \\ --out EUR.QC Each of the parameters corresponds to the following Paramter Value Description bfile EUR Informs plink that the input genotype files should have a prefix of EUR keep EUR.QC.fam Informs plink that we only want to use samples in EUR.QC.fam in the analysis extract EUR.QC.snplist Informs plink that we only want to use SNPs in EUR.QC.snplist in the analysis indep-pairwise 200 50 0.25 Informs plink that we wish to perform prunning with a window size of 200 variants, sliding across the genome with step size of 50 variants at a time, and filter out any SNPs with LD \\(r^2\\) higher than 0.25 out EUR.QC Informs plink that all output should have a prefix of EUR.QC This will generate two files 1) EUR.QC.prune.in and 2) EUR.QC.prune.out . All SNPs within EUR.QC.prune.in have a pairwise \\(r^2 < 0.25\\) . Heterozygosity rates can then be computed using plink : plink \\ --bfile EUR \\ --extract EUR.QC.prune.in \\ --keep EUR.QC.fam \\ --het \\ --out EUR.QC This will generate the EUR.QC.het file, which contains F coefficient estimates for assessing heterozygosity. We will remove individuals with F coefficients that are more than 3 standard deviation (SD) units from the mean, which can be performed using the following R command (assuming that you have R downloaded, then you can open an R session by typing R in your terminal): Without library dat <- read.table(\"EUR.QC.het\", header=T) # Read in the EUR.het file, specify it has header m <- mean(dat$F) # Calculate the mean s <- sd(dat$F) # Calculate the SD valid <- subset(dat, F <= m+3*s & F >= m-3*s) # Get any samples with F coefficient within 3 SD of the population mean write.table(valid[,c(1,2)], \"EUR.valid.sample\", quote=F, row.names=F) # print FID and IID for valid samples q() # exit R With data.table library(data.table) # Read in file dat <- fread(\"EUR.QC.het\") # Get samples with F coefficient within 3 SD of the population mean valid <- dat[F<=mean(F)+3*sd(F) & F>=mean(F)-3*sd(F)] # print FID and IID for valid samples fwrite(valid[,c(\"FID\",\"IID\")], \"EUR.valid.sample\", sep=\"\\t\") q() # exit R How many samples were excluded due to high heterozygosity rate? 2 samples were excluded # Ambiguous SNPs \u00b6 These were removed during the base data QC. # Mismatching SNPs \u00b6 SNPs that have mismatching alleles reported in the base and target data may be resolvable by strand-flipping the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target. This can be achieved with the following steps: 1. Load the bim file, the summary statistic and the QC SNP list into R Without data.table # Read in bim file bim <- read.table(\"EUR.bim\") colnames(bim) <- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\") # Read in QCed SNPs qc <- read.table(\"EUR.QC.snplist\", header = F, stringsAsFactors = F) # Read in the GWAS data height <- read.table(gzfile(\"Height.QC.gz\"), header = T, stringsAsFactors = F, sep=\"\\t\") # Change all alleles to upper case for easy comparison height$A1 <- toupper(height$A1) height$A2 <- toupper(height$A2) bim$B.A1 <- toupper(bim$B.A1) bim$B.A2 <- toupper(bim$B.A2) With data.table and magrittr # magrittr allow us to do piping, which help to reduce the # amount of intermediate data types library(data.table) library(magrittr) # Read in bim file bim <- fread(\"EUR.bim\") %>% # Note: . represents the output from previous step # The syntax here means, setnames of the data read from # the bim file, and replace the original column names by # the new names setnames(., colnames(.), c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")) %>% # And immediately change the alleles to upper cases .[,c(\"B.A1\",\"B.A2\"):=list(toupper(B.A1), toupper(B.A2))] # Read in summary statistic data (require data.table v1.12.0+) height <- fread(\"Height.QC.gz\") %>% # And immediately change the alleles to upper cases .[,c(\"A1\",\"A2\"):=list(toupper(A1), toupper(A2))] # Read in QCed SNPs qc <- fread(\"EUR.QC.snplist\", header=F) 2. Identify SNPs that require strand flipping Without data.table # Merge summary statistic with target info <- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\")) # Filter QCed SNPs info <- info[info$SNP %in% qc$V1,] # Function for finding the complementary allele complement <- function(x) { switch ( x, \"A\" = \"T\", \"C\" = \"G\", \"T\" = \"A\", \"G\" = \"C\", return(NA) ) } # Get SNPs that have the same alleles across base and target info.match <- subset(info, A1 == B.A1 & A2 == B.A2) # Identify SNPs that are complementary between base and target info$C.A1 <- sapply(info$B.A1, complement) info$C.A2 <- sapply(info$B.A2, complement) info.complement <- subset(info, A1 == C.A1 & A2 == C.A2) # Update the complementary alleles in the bim file # This allow us to match the allele in subsequent analysis complement.snps <- bim$SNP %in% info.complement$SNP bim[complement.snps,]$B.A1 <- sapply(bim[complement.snps,]$B.A1, complement) bim[complement.snps,]$B.A2 <- sapply(bim[complement.snps,]$B.A2, complement) With data.table and magrittr # Merge summary statistic with target info <- merge(bim, height, by=c(\"SNP\", \"CHR\", \"BP\")) %>% # And filter out QCed SNPs .[SNP %in% qc[,V1]] # Function for calculating the complementary allele complement <- function(x){ switch (x, \"A\" = \"T\", \"C\" = \"G\", \"T\" = \"A\", \"G\" = \"C\", return(NA) ) } # Get SNPs that have the same alleles across base and target info.match <- info[A1 == B.A1 & A2 == B.A2, SNP] # Identify SNPs that are complementary between base and target com.snps <- info[sapply(B.A1, complement) == A1 & sapply(B.A2, complement) == A2, SNP] # Now update the bim file bim[SNP %in% com.snps, c(\"B.A1\", \"B.A2\") := list(sapply(B.A1, complement), sapply(B.A2, complement))] 3. Identify SNPs that require recoding in the target (to ensure the coding allele in the target data is the effective allele in the base summary statistic) Without data.table # identify SNPs that need recoding info.recode <- subset(info, A1 == B.A2 & A2 == B.A1) # Update the recode SNPs recode.snps <- bim$SNP %in% info.recode$SNP tmp <- bim[recode.snps,]$B.A1 bim[recode.snps,]$B.A1 <- bim[recode.snps,]$B.A2 bim[recode.snps,]$B.A2 <- tmp # identify SNPs that need recoding & complement info.crecode <- subset(info, A1 == C.A2 & A2 == C.A1) # Update the recode + strand flip SNPs com.snps <- bim$SNP %in% info.crecode$SNP tmp <- bim[com.snps,]$B.A1 bim[com.snps,]$B.A1 <- as.character(sapply(bim[com.snps,]$B.A2, complement)) bim[com.snps,]$B.A2 <- as.character(sapply(tmp, complement)) # Output updated bim file write.table( bim, \"EUR.QC.adj.bim\", quote = F, row.names = F, col.names = F, sep=\"\\t\" ) With data.table and magrittr # identify SNPs that need recoding recode.snps <- info[B.A1==A2 & B.A2==A1, SNP] # Update the bim file bim[SNP %in% recode.snps, c(\"B.A1\", \"B.A2\") := list(B.A2, B.A1)] # identify SNPs that need recoding & complement com.recode <- info[sapply(B.A1, complement) == A2 & sapply(B.A2, complement) == A1, SNP] # Now update the bim file bim[SNP %in% com.recode, c(\"B.A1\", \"B.A2\") := list(sapply(B.A2, complement), sapply(B.A1, complement))] # Write the updated bim file fwrite(bim, \"EUR.QC.adj.bim\", col.names=F, sep=\"\\t\") 4. Identify SNPs that have different allele in base and target (usually due to difference in genome build or Indel) Without data.table mismatch <- bim$SNP[!(bim$SNP %in% info.match$SNP | bim$SNP %in% info.complement$SNP | bim$SNP %in% info.recode$SNP | bim$SNP %in% info.crecode$SNP)] write.table( mismatch, \"EUR.mismatch\", quote = F, row.names = F, col.names = F ) q() # exit R With data.table mismatch <- bim[!(SNP %in% info.match | SNP %in% com.snps | SNP %in% recode.snps | SNP %in% com.recode), SNP] write.table(mismatch, \"EUR.mismatch\", quote=F, row.names=F, col.names=F) q() # exit R 5. Replace EUR.bim with EUR.QC.adj.bim : # Make a back up mv EUR.bim EUR.bim.bk ln -s EUR.QC.adj.bim EUR.bim The above commands do the following: Rename EUR.bim to EUR.bim.bk Soft linking ( ln -s ) EUR.QC.adj.bim as EUR.bim Note Most PRS software will perform strand-flipping automatically, thus this step is usually not required. # Duplicate SNPs \u00b6 Make sure to remove any duplicate SNPs in your target data (these target data were simulated and so include no duplicated SNPs). # Sex chromosomes \u00b6 Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. A sex check can be performed in PLINK, in which individuals are called as females if their X chromosome homozygosity estimate (F statistic) is < 0.2 and as males if the estimate is > 0.8. Before performing a sex check, pruning should be performed (see here ). A sex check can then easily be conducted using plink plink \\ --bfile EUR \\ --extract EUR.QC.prune.in \\ --keep EUR.valid.sample \\ --check-sex \\ --out EUR.QC This will generate a file called EUR.QC.sexcheck containing the F-statistics for each individual. Individuals are typically called as being biologically male if the F-statistic is > 0.8 and biologically female if F < 0.2. Without library # Read in file valid <- read.table(\"EUR.valid.sample\", header=T) dat <- read.table(\"EUR.QC.sexcheck\", header=T) valid <- subset(dat, STATUS==\"OK\" & FID %in% valid$FID) write.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\", quote=F) q() # exit R With data.table library(data.table) # Read in file valid <- fread(\"EUR.valid.sample\") dat <- fread(\"EUR.QC.sexcheck\")[FID%in%valid$FID] fwrite(dat[STATUS==\"OK\",c(\"FID\",\"IID\")], \"EUR.QC.valid\", sep=\"\\t\") q() # exit R How many samples were excluded due mismatched Sex information? 4 samples were excluded # Sample overlap \u00b6 Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap). # Relatedness \u00b6 Closely related individuals in the target data may lead to overfitted results, limiting the generalisability of the results. Before calculating the relatedness, pruning should be performed (see here ). Individuals that have a first or second degree relative in the sample ( \\(\\hat{\\pi} > 0.125\\) ) can be removed with the following command: plink \\ --bfile EUR \\ --extract EUR.QC.prune.in \\ --keep EUR.QC.valid \\ --rel-cutoff 0.125 \\ --out EUR.QC How many related samples were excluded? 0 samples were excluded Note A greedy algorithm is used to remove closely related individuals in a way that optimizes the size of the sample retained. However, the algorithm is dependent on the random seed used, which can generate different results. Therefore, to reproduce the same result, you will need to specify the same random seed. PLINK's algorithm for removing related individuals does not account for the phenotype under study. To minimize the removal of cases of a disease, the following algorithm can be used instead: GreedyRelated . Generate final QC'ed target data file \u00b6 After performing the full analysis, you can generate a QC'ed data set with the following command: plink \\ --bfile EUR \\ --make-bed \\ --keep EUR.QC.rel.id \\ --out EUR.QC \\ --extract EUR.QC.snplist \\ --exclude EUR.mismatch","title":"2. Population Stratification"},{"location":"popstrat/#population-stratifacation","text":"","title":"Population Stratifacation"},{"location":"popstrat/#obtaining-the-1000-genome-reference-data-set","text":"We will be using data from the 1000 Genomes Project for the population stratification step. You can download using the following command wget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz The data will need to be converted into plink format with unique indentifiers created for each the SNPs with a missing rs-identifier: Note You will need plink in this section, which can be download from here . Install the program plink and include its location in your PATH directory, which allows us to use plink instead of ./plink in the commands below. If PLINK is not in your PATH directory and is instead in your working directory, replace all instances of plink in the tutorial with ./plink . plink --vcf ALL.2of4intersection.20100804.genotypes.vcf.gz --make-bed --out 1000genomes.genotypes plink --bfile 1000genomes.genotypes --set-missing-var-ids @:#[b37]\\$1,\\$2 --make-bed --out 1000genomes_nomissing.genotypes","title":"Obtaining the 1000 genome reference data set"},{"location":"popstrat/#define-variables-to-be-used-in-this-section","text":"input files and variables FILE_1K=1000genomes_nomissing.genotypes #1000 genomes file FILE_QC=qcout #file from qc tab FILE_PRUNEIN=plink.prune.in #snps in approximate linkage equilibrium GENO=0.02 #snp missingness filter INDV=0.02 #individual missingness filter MAF=0.05 #minor allele frequency filter HWE_CONTROL=1e-6 #hardy weinburg equilibrium filter define general file tags sep=\"_\" tagbed=\".bed\" tagbim=\".bim\" tagfam=\".fam\" tagmap=\".map\" tags for filtering 1000genome data TAG_1kG=\"1KG\" TAG_GENO=\"geno\" OUT1=\"$TAG_1kG$sep$TAG_GENO$sep$GENO\" TAG_MIND=\"mind\" OUT2=\"$OUT1$sep$TAG_MIND$sep$INDV\" TAG_MAF=\"maf\" OUT3=$OUT2$sep$TAG_MAF$sep$MAF TAG_extract=\"extract\" OUT4=$OUT3$sep$TAG_extract TAG_BUILD=\"samebuild\" OUT5=$OUT4$sep$TAG_BUILD TAG_REM=\"removeproblem\" OUT6=$OUT5$sep$TAG_REM tags for filtering QCed data TAG_QC=\"QCin\" OUT1_QC=$TAG_QC$sep$TAG_extract OUT2_QC=$OUT1_QC$sep$TAG_REM tag_euro=\"euro\" FILEQCEURO=$FILE_QC$sep$tag_euro","title":"Define Variables to be used in this section"},{"location":"popstrat/#qc-on-1000-genomes-data","text":"Remove variants based on missing genotype data. plink --bfile $FILE_1K --geno $GENO --make-bed --out $OUT1 Remove individuals based on missing genotype data plink --bfile $OUT1 --mind $INDV --allow-no-sex --make-bed --out $OUT2 Remove variants based on MAF plink --bfile $OUT2 --maf $MAF --make-bed --out $OUT3 Extract the variants present in our dataset from the 1000 genomes dataset awk '{print$2}' \"$FILE_QC$tagbim\"> QCFILE_SNPs.txt awk '{print$2}' \"$OUT3$tagbim\"> 1kG_temp.bim plink --bfile $OUT3 --extract QCFILE_SNPs.txt --make-bed --recode --out $OUT4","title":"QC on 1000 Genomes data."},{"location":"popstrat/#extract-the-variants-present-in-1000-genomes-dataset-from-your-dataset","text":"awk '{print$2}' $OUT4$tagbim > 1kG_SNPs.txt plink --bfile $FILE_QC --extract 1kG_SNPs.txt --recode --make-bed --out $OUT1_QC The datasets now contain the exact same variants.","title":"Extract the variants present in 1000 Genomes dataset from your dataset."},{"location":"popstrat/#change-build-on-1000-genomes-data-build-to-match-build-of-hapmap-data","text":"Note Look at Liftover tutorial to see how to move data set to another build. awk '{print$2,$4}' $OUT1_QC$tagmap > buildmap.txt # buildmap.txt contains one SNP-id and physical position per line. plink --bfile $OUT4 --update-map buildmap.txt --make-bed --out $OUT5","title":"Change build on 1000 Genomes data build to match build of HapMap data"},{"location":"popstrat/#merge-the-map-and-1000-genomes-data-sets","text":"Prior to merging 1000 Genomes data with the data we want to make sure that the files are mergeable, for this we conduct 3 steps: 1) Make sure the reference genome is similar in your data and the 1000 Genomes Project datasets 2) Resolve strand issues. 3) Remove the SNPs which after the previous two steps still differ between datasets 1) set reference genome awk '{print$2,$5}' $OUT5$tagbim > 1kg_ref-list.txt plink --bfile $OUT1_QC --reference-allele 1kg_ref-list.txt --make-bed --out Map-adj # The 1kG_MDS6 and the HapMap-adj have the same reference genome for all SNPs. 2) Resolve strand issues awk '{print$2,$5,$6}' $OUT5$tagbim > 1kGMDS_strand_tmp awk '{print$2,$5,$6}' Map-adj.bim > Map-adj_tmp sort 1kGMDS_strand_tmp Map-adj_tmp |uniq -u > all_differences.txt Flip SNPs for resolving strand issues awk '{print$1}' all_differences.txt | sort -u > flip_list.txt plink --bfile Map-adj --flip flip_list.txt --reference-allele 1kg_ref-list.txt --make-bed --out corrected_map Check for SNPs which are still problematic after they have been flipped. awk '{print$2,$5,$6}' corrected_map.bim > corrected_map_tmp sort 1kGMDS_strand_tmp corrected_map_tmp |uniq -u > uncorresponding_SNPs.txt 3) Remove problematic SNPs from your data and from the 1000 Genomes. awk '{print$1}' uncorresponding_SNPs.txt | sort -u > SNPs_for_exclusion.txt plink --bfile corrected_map --exclude SNPs_for_exclusion.txt --make-bed --out $OUT2_QC plink --bfile $OUT5 --exclude SNPs_for_exclusion.txt --make-bed --out $OUT6","title":"Merge the Map and 1000 Genomes data sets"},{"location":"popstrat/#merge-outdata-with-1000-genomes-data","text":"plink --bfile $OUT2_QC --bmerge $OUT6$tagbed $OUT6$tagbim $OUT6$tagfam --allow-no-sex --make-bed --out MDS_merge2","title":"Merge outdata with 1000 Genomes Data"},{"location":"popstrat/#perform-mds-on-map-ceu-data-anchored-by-1000-genomes-data","text":"","title":"Perform MDS on Map-CEU data anchored by 1000 Genomes data."},{"location":"popstrat/#using-a-set-of-pruned-snps","text":"plink --bfile MDS_merge2 --extract $FILE_PRUNEIN --genome --out MDS_merge2 plink --bfile MDS_merge2 --read-genome MDS_merge2.genome --cluster --mds-plot 10 --out MDS_merge2","title":"Using a set of pruned SNPs"},{"location":"popstrat/#mds-plot","text":"","title":"MDS-plot"},{"location":"popstrat/#download-the-file-with-population-information-of-the-1000-genomes-dataset","text":"wget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/20100804.ALL.panel","title":"Download the file with population information of the 1000 genomes dataset."},{"location":"popstrat/#the-file-20130502allpanel-contains-population-codes-of-the-individuals-of-1000-genomes","text":"","title":"The file 20130502.ALL.panel contains population codes of the individuals of 1000 genomes."},{"location":"popstrat/#convert-population-codes-into-superpopulation-codes-ie-aframrasn-and-eur","text":"awk '{print \\(1,\\) 1,$2}' 20100804.ALL.panel > race_1kG.txt","title":"Convert population codes into superpopulation codes (i.e., AFR,AMR,ASN, and EUR)."},{"location":"popstrat/#create-a-racefile-of-your-own-data","text":"awk '{print \\(1,\\) 2,\"-\"}' \\(OUT2_QC\\) tagfam > racefile_own.txt","title":"Create a racefile of your own data."},{"location":"popstrat/#concatenate-racefiles","text":"cat racefile_own.txt race_1kG.txt| sed -e '1i\\FID IID race' > MDS_merge2.pop sed -i -e \"1d\" MDS_merge2.pop cut -d \" \" -f 3- MDS_merge2.pop >temp.txt","title":"Concatenate racefiles."},{"location":"popstrat/#make-popfile-for-admixture-script","text":"mv temp.txt MDS_merge2.pop","title":"make popfile for admixture script"},{"location":"popstrat/#conda-install-c-bioconda-admixture","text":"","title":"conda install -c bioconda admixture"},{"location":"popstrat/#run-admixture-script","text":"qsub -cwd -pe smp 8 -l mem_free=32G -l scratch=100G -l h_rt=40:20:00 ad.sh admixture --supervised ./MDS_merge2.bed 12 > log_merge_admixture.out Rscript --no-save ../R/admixtureplot.R","title":"#####run admixture script"},{"location":"popstrat/#europeantxt-file-comes-from-admixture-script","text":"sed 's/JPT/ASN/g' race_1kG.txt>race_1kG2.txt sed 's/ASW/AFR/g' race_1kG2.txt>race_1kG3.txt sed 's/CEU/EUR/g' race_1kG3.txt>race_1kG4.txt sed 's/CHB/ASN/g' race_1kG4.txt>race_1kG5.txt sed 's/CHD/ASN/g' race_1kG5.txt>race_1kG6.txt sed 's/YRI/AFR/g' race_1kG6.txt>race_1kG7.txt sed 's/LWK/AFR/g' race_1kG7.txt>race_1kG8.txt sed 's/TSI/EUR/g' race_1kG8.txt>race_1kG9.txt sed 's/MXL/AMR/g' race_1kG9.txt>race_1kG10.txt sed 's/GBR/EUR/g' race_1kG10.txt>race_1kG11.txt sed 's/FIN/EUR/g' race_1kG11.txt>race_1kG12.txt sed 's/CHS/ASN/g' race_1kG12.txt>race_1kG13.txt sed 's/PUR/AMR/g' race_1kG13.txt>race_1kG14.txt","title":"european.txt file comes from admixture script"},{"location":"popstrat/#create-a-racefile-of-your-own-data_1","text":"awk '{print \\(1,\\) 2,\"OWN\"}' \\(OUT2_QC\\) tagfam > racefile_own.txt","title":"Create a racefile of your own data."},{"location":"popstrat/#concatenate-racefiles_1","text":"cat race_1kG14.txt racefile_own.txt | sed -e '1i\\FID IID race' > racefile.txt","title":"Concatenate racefiles."},{"location":"popstrat/#generate-population-stratification-plot","text":"Rscript ../R/MDS_merged.R","title":"Generate population stratification plot."},{"location":"popstrat/#exclude-ethnic-outliers","text":"","title":"Exclude ethnic outliers."},{"location":"popstrat/#select-individuals-in-your-own-data-below-cut-off-thresholds-the-cut-off-levels-are-not-fixed-ithresholds-but-have-to-be-determined-based-on-the-visualization-of-the-first-two-dimensions-to-exclude-ethnic-outliers-the-thresholds-need-to-be-set-around-the-cluster-of-population-of-interest","text":"","title":"Select individuals in your own data below cut-off thresholds. The cut-off levels are not fixed ithresholds but have to be determined based on the visualization of the first two dimensions. To exclude ethnic outliers, the thresholds need to be set around the cluster of population of interest."},{"location":"popstrat/#awk-if-4-004-5-003-print-12-mds_merge2mds-eur_mds_merge2","text":"","title":"awk '{ if ($4 &lt;-0.04 &amp;&amp; $5 &gt;0.03) print \\(1,\\)2 }' MDS_merge2.mds &gt; EUR_MDS_merge2"},{"location":"popstrat/#below-are-the-filters-used-for-my-own-ha-data","text":"","title":"below are the filters used for my own HA data"},{"location":"popstrat/#awk-if-4-01-4-005-5-01-5-003-print-12-mds_merge2mds-eur_mds_merge2","text":"","title":"awk '{ if ($4 &lt; 0.1 &amp;&amp; $4 &gt; -0.05 &amp;&amp; $5 &gt; -0.1 &amp;&amp; $5 &lt; 0.03) print \\(1,\\)2 }' MDS_merge2.mds &gt; EUR_MDS_merge2"},{"location":"popstrat/#tag_euroeuro","text":"","title":"tag_euro=\"euro\""},{"location":"popstrat/#fileqceurofile_qcseptag_euro","text":"","title":"FILEQCEURO=\\(FILE_QC\\)sep$tag_euro"},{"location":"popstrat/#plink-bfile-file_qc-keep-eur_mds_merge2-make-bed-out-fileqceuro","text":"","title":"plink --bfile $FILE_QC --keep EUR_MDS_merge2 --make-bed --out $FILEQCEURO"},{"location":"popstrat/#exclude-ethnic-outliers_1","text":"plink --bfile $FILE_QC --keep europeans.txt --make-bed --out $FILEQCEURO","title":"Exclude ethnic outliers."},{"location":"popstrat/#plink-bfile-file_qc-keep-eur_mds_merge2-make-bed-out-fileqceuro_1","text":"","title":"plink --bfile $FILE_QC --keep EUR_MDS_merge2 --make-bed --out $FILEQCEURO"},{"location":"popstrat/#hwe-limitations","text":"TAG_HWE_CONTROL=\"hwe_control\" OUTQCEURO= \\(FILEQCEURO\\) sep \\(TAG_HWE_CONTROL\\) sep$HWE_CONTROL echo \"plink --bfile $FILEQCEURO --hwe $HWE_CONTROL --make-bed --out $OUTQCEURO\" plink --bfile $FILEQCEURO --hwe $HWE_CONTROL --make-bed --out $OUTQCEURO","title":"HWE Limitations"},{"location":"popstrat/#in-this-tutorial-we-aim-to-remove-all-relatedness-from-our-dataset","text":"","title":"In this tutorial, we aim to remove all 'relatedness' from our dataset."},{"location":"popstrat/#to-demonstrate-that-the-majority-of-the-relatedness-was-due-to-parent-offspring-we-only-include-founders-individuals-without-parents-in-the-dataset","text":"found=\"founder\" plink --bfile \\(OUTQCEURO --filter-founders --make-bed --out \\(OUTQCEURO\\) sep\\) found","title":"To demonstrate that the majority of the relatedness was due to parent-offspring we only include founders (individuals without parents in the dataset)."},{"location":"popstrat/#check-for-cryptic-relatedness","text":"","title":"#Check for cryptic relatedness"},{"location":"popstrat/#install-king-and-run","text":"plink2 --bfile \\(OUTQCEURO\\) sep$found --make-king-table --king-table-filter 0.0884 sed 's/^#//' plink2.kin0 > kin.txt plink --bfile \\(OUTQCEURO\\) sep \\(found --missing Rscript ../R/Relatedness_cpw.R lowcover=\"unrelated\" OUTCOVER=\\) lowcover plink --bfile \\(OUTQCEURO\\) sep$found --remove 0.2_low_call_rate.txt --make-bed --out $OUTCOVER","title":"install king and run"},{"location":"popstrat/#create-covariates-based-on-mds","text":"","title":"Create covariates based on MDS."},{"location":"popstrat/#perform-an-mds-only-on-qccase-data-without-ethnic-outliers-the-values-of-the-10-mds-dimensions-are-subsequently-used-as-covariates-in-the-association-analysis-in-the-third-tutorial","text":"plink --bfile $OUTCOVER --extract plink.prune.in --genome --out $OUTCOVER tag_mds=\"MDS\" POPSTRATOUT= \\(OUTCOVER\\) sep$tag_mds taggenome=\".genome\" echo \"plink --bfile $OUTCOVER --read-genome \\(OUTCOVER\\) taggenome --cluster --mds-plot 10 --out $POPSTRATOUT\" plink --bfile $OUTCOVER --read-genome \\(OUTCOVER\\) taggenome --cluster --mds-plot 10 --out $POPSTRATOUT tag_dot_mds=\".mds\"","title":"Perform an MDS ONLY on qccase data without ethnic outliers. The values of the 10 MDS dimensions are subsequently used as covariates in the association analysis in the third tutorial."},{"location":"popstrat/#change-the-format-of-the-mds-file-into-a-plink-covariate-file","text":"awk '{print \\(1, (2, (4, (5, (6, \\(7,\\) 8,\\) 9,\\) 10,\\) 11,\\) 12,\\) 13}' \\(POPSTRATOUT\\) tag_dot_mds > covar_mds.txt","title":"Change the format of the .mds file into a plink covariate file."},{"location":"popstrat/#the-values-in-covar_mdstxt-will-be-used-as-covariates-to-adjust-for-remaining-population-stratification-in-the-third-tutorial-where-we-will-perform-a-genome-wide-association-analysis","text":"mv \\(OUTCOVER\\) tagbed ./popstratout.bed mv \\(OUTCOVER\\) tagbim ./popstratout.bim mv \\(OUTCOVER\\) tagfam ./popstratout.fam cp popstratout* ../3_Association_GWAS cp covar_mds.txt ../3_Association_GWAS cd ../3_Association_GWAS","title":"The values in covar_mds.txt will be used as covariates, to adjust for remaining population stratification, in the third tutorial where we will perform a genome-wide association analysis."},{"location":"popstrat/#sample-size","text":"We recommend that users only perform PRS analyses on target data of at least 100 individuals. The sample size of our target data here is 503 individuals.","title":"# Sample size"},{"location":"popstrat/#file-transfer","text":"Usually we do not need to download and transfer the target data file because it is typically generated locally. However, the file should contain an md5sum code in case we send the data file to collaborators who may want to confirm that the file has not changed during the transfer. What is the md5sum code for each of the target files? File md5sum EUR.bed 98bcef133f683b1272d3ea5f97742e0e EUR.bim 6b286002904880055a9c94e01522f059 EUR.cov 85ed18288c708e095385418517e9c3bd EUR.fam e7b856f0c7bcaffc8405926d08386e97 EUR.height dd445ce969a81cded20da5c88b82d4df","title":"# File transfer"},{"location":"popstrat/#genome-build","text":"As stated in the base data section, the genome build for our base and target data is the same, as it should be.","title":"# Genome build"},{"location":"popstrat/#standard-gwas-qc","text":"The target data must be quality controlled to at least the standards implemented in GWAS studies, e.g. removing SNPs with low genotyping rate, low minor allele frequency, out of Hardy-Weinberg Equilibrium, removing individuals with low genotyping rate (see Marees et al ). The following plink command applies some of these QC metrics to the target data: plink \\ --bfile EUR \\ --maf 0.01 \\ --hwe 1e-6 \\ --geno 0.01 \\ --mind 0.01 \\ --write-snplist \\ --make-just-fam \\ --out EUR.QC Each of the parameters corresponds to the following Paramter Value Description bfile EUR Informs plink that the input genotype files should have a prefix of EUR maf 0.01 Removes all SNPs with minor allele frequency less than 0.05. Genotyping errors typically have a larger influence on SNPs with low MAF. Studies with large sample sizes could apply a lower MAF threshold hwe 1e-6 Removes SNPs with low P-value from the Hardy-Weinberg Equilibrium Fisher's exact or chi-squared test. SNPs with significant P-values from the HWE test are more likely affected by genotyping error or the effects of natural selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases). When phenotype information is included, plink will automatically perform the filtering in the controls. geno 0.01 Excludes SNPs that are missing in a high fraction of subjects. A two-stage filtering process is usually performed (see Marees et al ). mind 0.01 Excludes individuals who have a high rate of genotype missingness, since this may indicate problems in the DNA sample or processing. (see Marees et al for more details). make-just-fam - Informs plink to only generate the QC'ed sample name to avoid generating the .bed file. write-snplist - Informs plink to only generate the QC'ed SNP list to avoid generating the .bed file. out EUR.QC Informs plink that all output should have a prefix of EUR.QC How many SNPs and samples were filtered? 14 samples were removed due to a high rate of genotype missingness 5,353 SNP were removed due to missing genotype data 944 SNPs were removed due to being out of Hardy-Weinberg Equilibrium 5,061 SNPs were removed due to low minor allele frequency Note Normally, we can generate a new genotype file using the new sample list. However, this will use up a lot of storage space. Using plink 's --extract , --exclude , --keep , --remove , --make-just-fam and --write-snplist functions, we can work solely on the list of samples and SNPs without duplicating the genotype file, reducing the storage space usage. Very high or low heterozygosity rates in individuals could be due to DNA contamination or to high levels of inbreeding. Therefore, samples with extreme heterozygosity are typically removed prior to downstream analyses. First, we perform prunning to remove highly correlated SNPs: plink \\ --bfile EUR \\ --keep EUR.QC.fam \\ --extract EUR.QC.snplist \\ --indep-pairwise 200 50 0.25 \\ --out EUR.QC Each of the parameters corresponds to the following Paramter Value Description bfile EUR Informs plink that the input genotype files should have a prefix of EUR keep EUR.QC.fam Informs plink that we only want to use samples in EUR.QC.fam in the analysis extract EUR.QC.snplist Informs plink that we only want to use SNPs in EUR.QC.snplist in the analysis indep-pairwise 200 50 0.25 Informs plink that we wish to perform prunning with a window size of 200 variants, sliding across the genome with step size of 50 variants at a time, and filter out any SNPs with LD \\(r^2\\) higher than 0.25 out EUR.QC Informs plink that all output should have a prefix of EUR.QC This will generate two files 1) EUR.QC.prune.in and 2) EUR.QC.prune.out . All SNPs within EUR.QC.prune.in have a pairwise \\(r^2 < 0.25\\) . Heterozygosity rates can then be computed using plink : plink \\ --bfile EUR \\ --extract EUR.QC.prune.in \\ --keep EUR.QC.fam \\ --het \\ --out EUR.QC This will generate the EUR.QC.het file, which contains F coefficient estimates for assessing heterozygosity. We will remove individuals with F coefficients that are more than 3 standard deviation (SD) units from the mean, which can be performed using the following R command (assuming that you have R downloaded, then you can open an R session by typing R in your terminal): Without library dat <- read.table(\"EUR.QC.het\", header=T) # Read in the EUR.het file, specify it has header m <- mean(dat$F) # Calculate the mean s <- sd(dat$F) # Calculate the SD valid <- subset(dat, F <= m+3*s & F >= m-3*s) # Get any samples with F coefficient within 3 SD of the population mean write.table(valid[,c(1,2)], \"EUR.valid.sample\", quote=F, row.names=F) # print FID and IID for valid samples q() # exit R With data.table library(data.table) # Read in file dat <- fread(\"EUR.QC.het\") # Get samples with F coefficient within 3 SD of the population mean valid <- dat[F<=mean(F)+3*sd(F) & F>=mean(F)-3*sd(F)] # print FID and IID for valid samples fwrite(valid[,c(\"FID\",\"IID\")], \"EUR.valid.sample\", sep=\"\\t\") q() # exit R How many samples were excluded due to high heterozygosity rate? 2 samples were excluded","title":"# Standard GWAS QC"},{"location":"popstrat/#ambiguous-snps","text":"These were removed during the base data QC.","title":"# Ambiguous SNPs"},{"location":"popstrat/#mismatching-snps","text":"SNPs that have mismatching alleles reported in the base and target data may be resolvable by strand-flipping the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target. This can be achieved with the following steps: 1. Load the bim file, the summary statistic and the QC SNP list into R Without data.table # Read in bim file bim <- read.table(\"EUR.bim\") colnames(bim) <- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\") # Read in QCed SNPs qc <- read.table(\"EUR.QC.snplist\", header = F, stringsAsFactors = F) # Read in the GWAS data height <- read.table(gzfile(\"Height.QC.gz\"), header = T, stringsAsFactors = F, sep=\"\\t\") # Change all alleles to upper case for easy comparison height$A1 <- toupper(height$A1) height$A2 <- toupper(height$A2) bim$B.A1 <- toupper(bim$B.A1) bim$B.A2 <- toupper(bim$B.A2) With data.table and magrittr # magrittr allow us to do piping, which help to reduce the # amount of intermediate data types library(data.table) library(magrittr) # Read in bim file bim <- fread(\"EUR.bim\") %>% # Note: . represents the output from previous step # The syntax here means, setnames of the data read from # the bim file, and replace the original column names by # the new names setnames(., colnames(.), c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")) %>% # And immediately change the alleles to upper cases .[,c(\"B.A1\",\"B.A2\"):=list(toupper(B.A1), toupper(B.A2))] # Read in summary statistic data (require data.table v1.12.0+) height <- fread(\"Height.QC.gz\") %>% # And immediately change the alleles to upper cases .[,c(\"A1\",\"A2\"):=list(toupper(A1), toupper(A2))] # Read in QCed SNPs qc <- fread(\"EUR.QC.snplist\", header=F) 2. Identify SNPs that require strand flipping Without data.table # Merge summary statistic with target info <- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\")) # Filter QCed SNPs info <- info[info$SNP %in% qc$V1,] # Function for finding the complementary allele complement <- function(x) { switch ( x, \"A\" = \"T\", \"C\" = \"G\", \"T\" = \"A\", \"G\" = \"C\", return(NA) ) } # Get SNPs that have the same alleles across base and target info.match <- subset(info, A1 == B.A1 & A2 == B.A2) # Identify SNPs that are complementary between base and target info$C.A1 <- sapply(info$B.A1, complement) info$C.A2 <- sapply(info$B.A2, complement) info.complement <- subset(info, A1 == C.A1 & A2 == C.A2) # Update the complementary alleles in the bim file # This allow us to match the allele in subsequent analysis complement.snps <- bim$SNP %in% info.complement$SNP bim[complement.snps,]$B.A1 <- sapply(bim[complement.snps,]$B.A1, complement) bim[complement.snps,]$B.A2 <- sapply(bim[complement.snps,]$B.A2, complement) With data.table and magrittr # Merge summary statistic with target info <- merge(bim, height, by=c(\"SNP\", \"CHR\", \"BP\")) %>% # And filter out QCed SNPs .[SNP %in% qc[,V1]] # Function for calculating the complementary allele complement <- function(x){ switch (x, \"A\" = \"T\", \"C\" = \"G\", \"T\" = \"A\", \"G\" = \"C\", return(NA) ) } # Get SNPs that have the same alleles across base and target info.match <- info[A1 == B.A1 & A2 == B.A2, SNP] # Identify SNPs that are complementary between base and target com.snps <- info[sapply(B.A1, complement) == A1 & sapply(B.A2, complement) == A2, SNP] # Now update the bim file bim[SNP %in% com.snps, c(\"B.A1\", \"B.A2\") := list(sapply(B.A1, complement), sapply(B.A2, complement))] 3. Identify SNPs that require recoding in the target (to ensure the coding allele in the target data is the effective allele in the base summary statistic) Without data.table # identify SNPs that need recoding info.recode <- subset(info, A1 == B.A2 & A2 == B.A1) # Update the recode SNPs recode.snps <- bim$SNP %in% info.recode$SNP tmp <- bim[recode.snps,]$B.A1 bim[recode.snps,]$B.A1 <- bim[recode.snps,]$B.A2 bim[recode.snps,]$B.A2 <- tmp # identify SNPs that need recoding & complement info.crecode <- subset(info, A1 == C.A2 & A2 == C.A1) # Update the recode + strand flip SNPs com.snps <- bim$SNP %in% info.crecode$SNP tmp <- bim[com.snps,]$B.A1 bim[com.snps,]$B.A1 <- as.character(sapply(bim[com.snps,]$B.A2, complement)) bim[com.snps,]$B.A2 <- as.character(sapply(tmp, complement)) # Output updated bim file write.table( bim, \"EUR.QC.adj.bim\", quote = F, row.names = F, col.names = F, sep=\"\\t\" ) With data.table and magrittr # identify SNPs that need recoding recode.snps <- info[B.A1==A2 & B.A2==A1, SNP] # Update the bim file bim[SNP %in% recode.snps, c(\"B.A1\", \"B.A2\") := list(B.A2, B.A1)] # identify SNPs that need recoding & complement com.recode <- info[sapply(B.A1, complement) == A2 & sapply(B.A2, complement) == A1, SNP] # Now update the bim file bim[SNP %in% com.recode, c(\"B.A1\", \"B.A2\") := list(sapply(B.A2, complement), sapply(B.A1, complement))] # Write the updated bim file fwrite(bim, \"EUR.QC.adj.bim\", col.names=F, sep=\"\\t\") 4. Identify SNPs that have different allele in base and target (usually due to difference in genome build or Indel) Without data.table mismatch <- bim$SNP[!(bim$SNP %in% info.match$SNP | bim$SNP %in% info.complement$SNP | bim$SNP %in% info.recode$SNP | bim$SNP %in% info.crecode$SNP)] write.table( mismatch, \"EUR.mismatch\", quote = F, row.names = F, col.names = F ) q() # exit R With data.table mismatch <- bim[!(SNP %in% info.match | SNP %in% com.snps | SNP %in% recode.snps | SNP %in% com.recode), SNP] write.table(mismatch, \"EUR.mismatch\", quote=F, row.names=F, col.names=F) q() # exit R 5. Replace EUR.bim with EUR.QC.adj.bim : # Make a back up mv EUR.bim EUR.bim.bk ln -s EUR.QC.adj.bim EUR.bim The above commands do the following: Rename EUR.bim to EUR.bim.bk Soft linking ( ln -s ) EUR.QC.adj.bim as EUR.bim Note Most PRS software will perform strand-flipping automatically, thus this step is usually not required.","title":"# Mismatching SNPs"},{"location":"popstrat/#duplicate-snps","text":"Make sure to remove any duplicate SNPs in your target data (these target data were simulated and so include no duplicated SNPs).","title":"# Duplicate SNPs"},{"location":"popstrat/#sex-chromosomes","text":"Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. A sex check can be performed in PLINK, in which individuals are called as females if their X chromosome homozygosity estimate (F statistic) is < 0.2 and as males if the estimate is > 0.8. Before performing a sex check, pruning should be performed (see here ). A sex check can then easily be conducted using plink plink \\ --bfile EUR \\ --extract EUR.QC.prune.in \\ --keep EUR.valid.sample \\ --check-sex \\ --out EUR.QC This will generate a file called EUR.QC.sexcheck containing the F-statistics for each individual. Individuals are typically called as being biologically male if the F-statistic is > 0.8 and biologically female if F < 0.2. Without library # Read in file valid <- read.table(\"EUR.valid.sample\", header=T) dat <- read.table(\"EUR.QC.sexcheck\", header=T) valid <- subset(dat, STATUS==\"OK\" & FID %in% valid$FID) write.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\", quote=F) q() # exit R With data.table library(data.table) # Read in file valid <- fread(\"EUR.valid.sample\") dat <- fread(\"EUR.QC.sexcheck\")[FID%in%valid$FID] fwrite(dat[STATUS==\"OK\",c(\"FID\",\"IID\")], \"EUR.QC.valid\", sep=\"\\t\") q() # exit R How many samples were excluded due mismatched Sex information? 4 samples were excluded","title":"# Sex chromosomes"},{"location":"popstrat/#sample-overlap","text":"Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).","title":"# Sample overlap"},{"location":"popstrat/#relatedness","text":"Closely related individuals in the target data may lead to overfitted results, limiting the generalisability of the results. Before calculating the relatedness, pruning should be performed (see here ). Individuals that have a first or second degree relative in the sample ( \\(\\hat{\\pi} > 0.125\\) ) can be removed with the following command: plink \\ --bfile EUR \\ --extract EUR.QC.prune.in \\ --keep EUR.QC.valid \\ --rel-cutoff 0.125 \\ --out EUR.QC How many related samples were excluded? 0 samples were excluded Note A greedy algorithm is used to remove closely related individuals in a way that optimizes the size of the sample retained. However, the algorithm is dependent on the random seed used, which can generate different results. Therefore, to reproduce the same result, you will need to specify the same random seed. PLINK's algorithm for removing related individuals does not account for the phenotype under study. To minimize the removal of cases of a disease, the following algorithm can be used instead: GreedyRelated .","title":"# Relatedness"},{"location":"popstrat/#generate-final-qced-target-data-file","text":"After performing the full analysis, you can generate a QC'ed data set with the following command: plink \\ --bfile EUR \\ --make-bed \\ --keep EUR.QC.rel.id \\ --out EUR.QC \\ --extract EUR.QC.snplist \\ --exclude EUR.mismatch","title":"Generate final QC'ed target data file"},{"location":"prsice/","text":"Background \u00b6 PRSice-2 is one of the dedicated PRS programs which automates many of the steps from the previous page that used a sequence of PLINK functions (plus some QC steps). On this page you will run a PRS analysis using PRSice-2, which implements the standard C+T method. Obtaining PRSice-2 \u00b6 PRSice-2 can be downloaded from: Operating System Link Linux 64-bit v2.3.3 OS X 64-bit v2.3.3 and can be directly used after extracting the file. In this tutorial, you will only need PRSice.R and PRSice_XXX where XXX is the operation system Required Data \u00b6 This analysis assumes that you have the following files (or you can download it from here ): File Name Description Height.QC.gz The post QC base data file. While PRSice-2 can automatically apply most filtering on the base file, it cannot remove duplicated SNPs EUR.QC.bed This file contains the genotype data that passed the QC steps EUR.QC.bim This file contains the list of SNPs that passed the QC steps EUR.QC.fam This file contains the samples that passed the QC steps EUR.height This file contains the phenotype data of the samples EUR.cov This file contains the covariates of the samples EUR.eigenvec This file contains the principal components (PCs) of the samples Running PRS analysis \u00b6 To run PRSice-2 we need a single covariate file, and therefore our covariate file and PCs file should be combined. This can be done with R as follows: without data.table covariate <- read.table(\"EUR.cov\", header=T) pcs <- read.table(\"EUR.eigenvec\", header=F) colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6)) cov <- merge(covariate, pcs, by=c(\"FID\", \"IID\")) write.table(cov,\"EUR.covariate\", quote=F, row.names=F) q() with data.table library(data.table) covariate <- fread(\"EUR.cov\") pcs <- fread(\"EUR.eigenvec\", header=F) colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6)) cov <- merge(covariate, pcs) fwrite(cov,\"EUR.covariate\", sep=\"\\t\") q() which generates EUR.cov . PRSice-2 can then be run to obtain the PRS results as follows: Linux Rscript PRSice.R \\ --prsice PRSice_linux \\ --base Height.QC.gz \\ --target EUR.QC \\ --binary-target F \\ --pheno EUR.height \\ --cov EUR.covariate \\ --base-maf MAF:0.01 \\ --base-info INFO:0.8 \\ --stat OR \\ --or \\ --out EUR OS X Rscript PRSice.R \\ --prsice PRSice_mac \\ --base Height.QC.gz \\ --target EUR.QC \\ --binary-target F \\ --pheno EUR.height \\ --cov EUR.covariate \\ --base-maf MAF:0.01 \\ --base-info INFO:0.8 \\ --stat OR \\ --or \\ --out EUR Windows Rscript PRSice.R ^ --prsice PRSice_win64.exe ^ --base Height.QC.gz ^ --target EUR.QC ^ --binary-target F ^ --pheno EUR.height ^ --cov EUR.covariate ^ --base-maf MAF:0.05 ^ --base-info INFO:0.8 ^ --stat OR ^ --or ^ --out EUR The meaning of the parameters are as follow: Paramter Value Description prsice PRSice_xxx Informs PRSice.R that the location of the PRSice binary base Height.QC.gz Informs PRSice that the name of the GWAS summary statistic target EUR.QC Informs PRSice that the input genotype files should have a prefix of EUR.QC binary-target F Indicate if the phenotype of interest is a binary trait. F for no pheno EUR.height Provide PRSice with the phenotype file cov EUR.covariate Provide PRSice with the covariate file base-maf MAF:0.05 Filter out SNPs with MAF < 0.05 in the GWAS summary statistics, using information in the MAF column base-info INFO:0.8 Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column stat OR Column name of the column containing the effect size or - Inform PRSice that the effect size is an Odd Ratio out EUR Informs PRSice that all output should have a prefix of EUR This will automatically perform \"high-resolution scoring\" and generate the \"best-fit\" PRS (in EUR.best ), with associated plots of the results. Users should read Section 4.6 of our paper to learn more about issues relating to overfitting in PRS analyses. Which P-value threshold generates the \"best-fit\" PRS? 0.13995 How much phenotypic variation does the \"best-fit\" PRS explain? 0.166117","title":"Background"},{"location":"prsice/#background","text":"PRSice-2 is one of the dedicated PRS programs which automates many of the steps from the previous page that used a sequence of PLINK functions (plus some QC steps). On this page you will run a PRS analysis using PRSice-2, which implements the standard C+T method.","title":"Background"},{"location":"prsice/#obtaining-prsice-2","text":"PRSice-2 can be downloaded from: Operating System Link Linux 64-bit v2.3.3 OS X 64-bit v2.3.3 and can be directly used after extracting the file. In this tutorial, you will only need PRSice.R and PRSice_XXX where XXX is the operation system","title":"Obtaining PRSice-2"},{"location":"prsice/#required-data","text":"This analysis assumes that you have the following files (or you can download it from here ): File Name Description Height.QC.gz The post QC base data file. While PRSice-2 can automatically apply most filtering on the base file, it cannot remove duplicated SNPs EUR.QC.bed This file contains the genotype data that passed the QC steps EUR.QC.bim This file contains the list of SNPs that passed the QC steps EUR.QC.fam This file contains the samples that passed the QC steps EUR.height This file contains the phenotype data of the samples EUR.cov This file contains the covariates of the samples EUR.eigenvec This file contains the principal components (PCs) of the samples","title":"Required Data"},{"location":"prsice/#running-prs-analysis","text":"To run PRSice-2 we need a single covariate file, and therefore our covariate file and PCs file should be combined. This can be done with R as follows: without data.table covariate <- read.table(\"EUR.cov\", header=T) pcs <- read.table(\"EUR.eigenvec\", header=F) colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6)) cov <- merge(covariate, pcs, by=c(\"FID\", \"IID\")) write.table(cov,\"EUR.covariate\", quote=F, row.names=F) q() with data.table library(data.table) covariate <- fread(\"EUR.cov\") pcs <- fread(\"EUR.eigenvec\", header=F) colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6)) cov <- merge(covariate, pcs) fwrite(cov,\"EUR.covariate\", sep=\"\\t\") q() which generates EUR.cov . PRSice-2 can then be run to obtain the PRS results as follows: Linux Rscript PRSice.R \\ --prsice PRSice_linux \\ --base Height.QC.gz \\ --target EUR.QC \\ --binary-target F \\ --pheno EUR.height \\ --cov EUR.covariate \\ --base-maf MAF:0.01 \\ --base-info INFO:0.8 \\ --stat OR \\ --or \\ --out EUR OS X Rscript PRSice.R \\ --prsice PRSice_mac \\ --base Height.QC.gz \\ --target EUR.QC \\ --binary-target F \\ --pheno EUR.height \\ --cov EUR.covariate \\ --base-maf MAF:0.01 \\ --base-info INFO:0.8 \\ --stat OR \\ --or \\ --out EUR Windows Rscript PRSice.R ^ --prsice PRSice_win64.exe ^ --base Height.QC.gz ^ --target EUR.QC ^ --binary-target F ^ --pheno EUR.height ^ --cov EUR.covariate ^ --base-maf MAF:0.05 ^ --base-info INFO:0.8 ^ --stat OR ^ --or ^ --out EUR The meaning of the parameters are as follow: Paramter Value Description prsice PRSice_xxx Informs PRSice.R that the location of the PRSice binary base Height.QC.gz Informs PRSice that the name of the GWAS summary statistic target EUR.QC Informs PRSice that the input genotype files should have a prefix of EUR.QC binary-target F Indicate if the phenotype of interest is a binary trait. F for no pheno EUR.height Provide PRSice with the phenotype file cov EUR.covariate Provide PRSice with the covariate file base-maf MAF:0.05 Filter out SNPs with MAF < 0.05 in the GWAS summary statistics, using information in the MAF column base-info INFO:0.8 Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column stat OR Column name of the column containing the effect size or - Inform PRSice that the effect size is an Odd Ratio out EUR Informs PRSice that all output should have a prefix of EUR This will automatically perform \"high-resolution scoring\" and generate the \"best-fit\" PRS (in EUR.best ), with associated plots of the results. Users should read Section 4.6 of our paper to learn more about issues relating to overfitting in PRS analyses. Which P-value threshold generates the \"best-fit\" PRS? 0.13995 How much phenotypic variation does the \"best-fit\" PRS explain? 0.166117","title":"Running PRS analysis"}]}